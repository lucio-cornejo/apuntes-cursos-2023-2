[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Learning 1",
    "section": "",
    "text": "Sílabo"
  },
  {
    "objectID": "apuntes/clase-01.html#sobre-el-curso",
    "href": "apuntes/clase-01.html#sobre-el-curso",
    "title": "Apuntes de clase",
    "section": "Sobre el curso",
    "text": "Sobre el curso\nCasi toda la teoría del curso está contenida en ISLR, libro principal de la bibliografía del curso.\nLas listas deben ir avanzándose, pues la entrega oficial consistirá de modificaciones sobre algunos problemas de esas listas, con solo uno o dos días de plazo para la entrega.\nSolo habrá, most likely, máximo tres tareas académicas, pero ninguna se elimina.\nLas tareas no son las que están actualmente en Paideia, pero se basarán en las listas ya subidas.\nMáximo grupos de 4 para los grupos de las tareas; aunque puede ser individual también."
  },
  {
    "objectID": "apuntes/clase-01.html#introducción",
    "href": "apuntes/clase-01.html#introducción",
    "title": "Apuntes de clase",
    "section": "Introducción",
    "text": "Introducción\n\nMain goal:\n\nPredicción (no inferencia, eso se ve en otros cursos)\nFrom dataset, saber qué algoritmo de aprendizaje estadístico escoger, además de saber comunicar los hallazgos encontrados.\n\nHay más similitudes que diferencias entre Statistical Learning y Machine Learning (Aprendizaje de Máquina).\n\n\n¿Qué es Statistical Learning?\n\nSet of tools to understand data.\nDistinción principal: Supervisado vs No Supervisado\nCadena de stat. learning.: modelo -&gt; método -&gt; algoritmo -&gt; análisis -&gt; interpretación\nObjetivos principales:\n\nPredecir: Qué va a pasar\nInferencia: Cómo va a pasar\n\nEn Estadística, es muy importante considerar de dónde vienen los datos (muestreados under some probabilistic distribution).\n\n\n\nStatistical Learning vs Data Science\nData Science también busca obtener info a partir de datos, pero siempre require una implementación. Esto pues Data Science combina diversas disciplinas (math, CS, etc) para darles un enfoque pragmático.\nEste enfoque pragmático no es necesario en Statistical Learning.\nAmbos enfoques son importantes en la sociedad."
  },
  {
    "objectID": "apuntes/clase-01.html#aprendizaje-estadístico",
    "href": "apuntes/clase-01.html#aprendizaje-estadístico",
    "title": "Apuntes de clase",
    "section": "Aprendizaje Estadístico",
    "text": "Aprendizaje Estadístico\n\n¿Qué es?\nProceso de aprendizaje a partir de los datos.\n\nA partir de la aplicación de modelos a un conjunto de entrenamiento podemos:\n\nExtraer conclusiones acerca de las relaciones entre las variables inferencia.\nEncontrar una función predictiva para nuevas observaciones predicción.\n\n\n\n\nEl problema del Aprendizaje Supervisado\n\nPunto de partida:\n\nMedición del resultado \\(Y\\) (variable dependiente/respuesta/objetivo)\nVector de \\(p\\) mediciones predictoras \\(X = (X_1, \\cdots, X_p)\\), también llamadas entradas/regresores/covariables/características o variables independientes.\nEn problemas de regresión, \\(Y\\) es cuantitativa; en problemas de clasificación, \\(Y\\) toma valores en un conjunto finito y desordenado de clases o atributos predefinidos.\nTenemos datos de entrenamiento \\((x_1, Y_1), \\cdots, (x_n, Y_n)\\).\n\nA partir del training set, nos gustaría:\n\nPredecir nuevos casos de prueba.\nComprender como se relacionan las variables.\nEvaluar la calidad de predicciones e inferencias.\n\nLa variable respuesta supervisa nuestro análisis.\n\n\n\nEl problema del Aprendizaje No Supervisado\n\nNo hay variable respuesta.\nSe buscan patrones o agrupaciones (ocultas) en los datos, para obtener información y comprensión.\nHay más subjetividad al momento de comparar modelos; por ello importa mucho más el conocimiento sobre el área de aplicación (field experts).\n\n\n\nFilosofía general\n\nLos métodos más simples a menudo funcionan tan bien como los más complicados.\n\n\n\nStatistical Learning vs Machine Learning\n\n\\(\\text{ML} \\subset \\text{AI}\\) (algoritmos)\n\\(\\text{SL} \\subset \\text{Statistics}\\) (modelos)\nPresentan un mayor enfoque en:\n\nML: Precisión de la predicción y aplicaciones a gran escala.\nSL: Modelos, su interpretabilidad, precisión e incertidumbre.\n\nMétodo escalable: Al añadir más datos o más variables, la precisión no se reduce.\nSL y ML emplean casi las mismas técnicas.\nComparado a un curso de ML, en este curso nos enfocaremos más en comprender los modelos que usaremos, cómo funcionan."
  },
  {
    "objectID": "apuntes/clase-01.html#lista-de-ejercicios",
    "href": "apuntes/clase-01.html#lista-de-ejercicios",
    "title": "Apuntes de clase",
    "section": "Lista de ejercicios",
    "text": "Lista de ejercicios\nLista 1"
  },
  {
    "objectID": "apuntes/clase-02.html#objetivo-de-statistical-learning",
    "href": "apuntes/clase-02.html#objetivo-de-statistical-learning",
    "title": "Apuntes de clase",
    "section": "Objetivo de Statistical Learning",
    "text": "Objetivo de Statistical Learning\n\nSuposiciones:\n\nSe observa una variable respuesta cuantitativa \\(Y\\) .\nSe cuentan con \\(p\\) predictores \\(x_1, \\dots, x_n\\) .\nExiste una función \\(f\\) tal que \\(Y = f(x) + \\epsilon\\) .\nDonde \\(\\epsilon\\), aleatorio, es independiente de \\(X\\), y tiene media cero.\n\nEl término \\(\\epsilon\\) nos permite hacer inferencia … las predicciones tienen un intervalo de confianza.\nOBJETIVO: Estimar \\(f\\) .\nRespecto a la inferencia posible tras estimar \\(f\\), se refieren a generalizar estadísiticamente la relación entre los predictors y la response (ejemplo: analizar los coeficientes tras regresión lineal); decir si los atributos son estadísticamente significativos.\n\n\nMotivo 1: Predicción\n\nObjetivo: Predecir, con la mayor precisión posible, la respuesta \\(Y\\), dadas nuevas observaciones \\(x\\) de las covariables.\n\n\\[\n\\hat{Y} = \\hat{f}(x)\n\\]\n\nPara predicción, no requerimos la forma exacta de \\(\\hat{f}\\) .\nExisten dos términos que influyen en la precisión de \\(\\hat{Y}\\), como prediccion de \\(\\hat{Y}\\) :\n\nError reducible: Proviene de nuestra estimación \\(\\hat{f}\\) de \\(f\\) .\nError ireducible: Proviene del término del error \\(\\epsilon\\) y no puede reducirse mejorando \\(\\hat{f}\\) .\n\nFijada la estimación \\(\\hat{f}\\), respeto a la respuesta \\(Y\\) y un conjunto de predictores \\(X\\), se cumple\n\n\\[\nE \\left[ \\left( Y - \\hat{Y} \\right)^2\\right] =\n\\underbrace{E\\left[\\left( f(X) - \\hat{f}(X) \\right)^2\\right]}_{\\text{error reducible}}\n+ \\underbrace{\\text{var}(\\epsilon)}_{\\text{error irreducible}}\n\\]\n\n\nMotivo 2: Inferencia\n\nObjetivo: Comprender cómo la variable respuesta se ve afectada por los diversos predictores (covariables).\nRequerimos la forma exacta de \\(\\hat{f}\\):\n\n¿Qué predictores están asociados con la respuesta?\n¿Cuál es la relación entre la respuesta y cada predictor?\n¿La relación puede ser lineal, o se requiere un modelo más complejo?"
  },
  {
    "objectID": "apuntes/clase-02.html#regresión-y-clasificación",
    "href": "apuntes/clase-02.html#regresión-y-clasificación",
    "title": "Apuntes de clase",
    "section": "Regresión y Clasificación",
    "text": "Regresión y Clasificación\n\nRegresión: Cuando la variable respuesta es numérica.\nClasificación Cuando la variable respuesta es categórica."
  },
  {
    "objectID": "apuntes/clase-02.html#estimación-de-f",
    "href": "apuntes/clase-02.html#estimación-de-f",
    "title": "Apuntes de clase",
    "section": "Estimación de \\(f\\)",
    "text": "Estimación de \\(f\\)\n\nMain idea:\n\nUsar un conjunto de datos de entrenamiento \\(\\left( x_1, y_1 \\right), \\dots, \\left( x_n, y_n \\right)\\) para hallar una estimación \\(\\hat{f}\\), tal que \\(\\hat{f}(X) \\approx Y\\), para cada \\(\\left( X, Y \\right)\\)\n\nPara predicción, NUNCA evaluar la estimación \\(\\hat{f}\\) en una observación de entrenamiento \\(X\\) .\nPresenta dos enfoques principales: Param. y No param. .\n\n\nMétodos paramétricos\n\nSteps:\n\nFijar una forma para \\(f\\) . 1 Estimar los parámetros desconocidos de \\(f\\), unsando el conjunto de entrenamiento.\n\n\n\n\nMétodos no paramétricos\n\nBuscan una estimación de \\(f\\), sin hacer suposiciones explícitas de la función \\(f\\) .\nEn cierto sentido, se consideran infinitos parámetros.\nEjemplo: Algoritmo de los \\(K\\)-vecinos.\nParámetro: Constante del modelo, que se estima.\nHiperparámetro: Constante del modelo, que se escoge libremente. Por ejemplo, el valor \\(K\\) en el algoritmo de \\(K\\)-means.\nLos hiperparámetros se pueden calibrar para obtener un nivel de adecuado de flexibilidad para el modelo.\n\n\n\nParam. vs No param.\n\nSuelen ser de mayor interpretabilidad: Paramétrico.\nTienden a ser más flexibles: No paramétricos.\nSuelen tener mayor complejidad computacional: No paramétricos.\nSuele requerir una mayor cantidad de datos: No paramétricos.\nNo necesariamente un método no paramétrico siempre produce predicciones más precisas, comparado a un método paramétrico.\n\n\n\n\n\n\nComparación"
  },
  {
    "objectID": "apuntes/clase-02.html#prediction-accuracy-vs-interpretabilidad",
    "href": "apuntes/clase-02.html#prediction-accuracy-vs-interpretabilidad",
    "title": "Apuntes de clase",
    "section": "Prediction accuracy vs Interpretabilidad",
    "text": "Prediction accuracy vs Interpretabilidad\n\nMétodos inflexibles (o rígidos), son aquellos que tienen fuerte restricciones sobre la forma de \\(f\\) .\nLa elección de un método flexible o inflexible depende del objetivo en mente:\n\nIf goal is inferencia, then se prefiere métodos inflexibles\nIf goal is predicción, then se prefiere métodos flexibles.\n\nSobreajuste: Ocurre cuando \\(\\hat{f}\\) se ajusta demasiado a los datos observados.\nSubajuste: Ocurre cuando \\(\\hat{f}\\) es demasiado rígida para capturar la estructura subyacente de los datos."
  },
  {
    "objectID": "apuntes/clase-02.html#ejercicio",
    "href": "apuntes/clase-02.html#ejercicio",
    "title": "Apuntes de clase",
    "section": "EJERCICIO",
    "text": "EJERCICIO\nResolver la lista 1 publicada en Paideia, al menos hasta el item c (no included)."
  },
  {
    "objectID": "apuntes/clase-02.html#evaluación-de-la-precisión-del-modelo",
    "href": "apuntes/clase-02.html#evaluación-de-la-precisión-del-modelo",
    "title": "Apuntes de clase",
    "section": "Evaluación de la precisión del modelo",
    "text": "Evaluación de la precisión del modelo\n\nNingún método domina a todos los demás sobre todos conjuntos de datos posibles.\n\n\nFunción pérdida\n\nPara variable respuesta numérica, las métricas \\(L1\\) y \\(L2\\) suelen usarse.\nPara response categórica, se puede usar la asignación 0 (si \\(\\hat{y}_i = y_i\\) ); y, 1, caso contrario.\nEn problemas de regresión, suele emplearse la pérdida cuadrática (\\(L2\\)).\n\n\n\nMSE de entrenamiento\n\nNotación: \\(\\text{MSE}_{\\text{train}} = \\dfrac{1}{n} \\displaystyle{ \\sum_{i=1}^{n}\\left( y_i - \\hat{f}(x_i) \\right)^2}\\)\nCuando se evalúa \\(\\hat{f}\\) en una observación de entrenamiento, no es posible saber si la predicción fue precisa debido a que el modelo aprendió o porque para el modelo se empleó el valor observado para la response variable (caso modelo plagió).\n\n\n\nMSE de prueba\n\nEvaluamos el modelo con una muestra de observaciones que no fue usada para entrenar al modelo. Esta muestra se denomina datos de prueba (test).\nPara un conjunto de \\(n_0\\) observaciones de prueba \\(\\left( x_{0j}, y_{0j} \\right)\\), se define:\n\n\\(\\text{MSE}_{\\text{test}} = \\dfrac{1}{n_0} \\displaystyle{ \\sum_{j=1}^{n_0}\\left( y_{0j} - \\hat{f}(x_{0j}) \\right)^2}\\)"
  },
  {
    "objectID": "apuntes/clase-03.html#bias-variance-tradeoff",
    "href": "apuntes/clase-03.html#bias-variance-tradeoff",
    "title": "Apuntes de clase",
    "section": "Bias-variance tradeoff",
    "text": "Bias-variance tradeoff\nFijando un valor \\(x_0\\) para los predictores, y considerando una familia de training datasets, cada uno de esos training sets produce una estimación \\(\\hat{f}\\) de la función \\(f\\).\nAhora, considere el siguiente resultado:\n\nTheorem 1 \\[\nE \\left[\\left( Y - \\hat{f}\\left( x_o \\right) \\right)^2\\right]\n= \\text{ Var}\\left( \\epsilon \\right) +\n\\text{ Var}\\left( \\hat{f}\\left( x_0 \\right) \\right) +\n\\left[\\text{ Bias}\\left( \\hat{f}\\left( x_0 \\right) \\right)\\right]^2\n\\]\n\nEl sesgo consiste en cómo se aleja el valor real de la variable, en comparacion con el promedio de las estimaciones.\nModelos que suelen tenor menor sesgo, suelen tener mayor varianza, y viceversa.\n\nProposition 1 Para modelos más flexibles, la varianza se incrementa y el sesgo disminuye. (not aaalways true).\n\n\nProposition 2 Resulta que el punto donde el \\(\\text{ MSE }_{test}\\) alcanza un mínimo (en el eje Y, siendo el eje X el nivel de flexibilidad), a vecese coincide con el punto donde se intersectan el bias y varianza de la estimación \\(\\hat{f}\\)\n\n\n\n\n\n\nBias-variance tradeoff\n\n\n\n\n\nResumen:\n\nA medida que aumenta la complejidad (y, por tanto la flexibilidad) de un modelo, el modelo se vuelve más adaptable a estructuras subyacentes y cae el error de entrenaminto (sobreajuste)\nEl error de prueba es el error de predicción sobre una muestra de prueba.\nLos modelos inflexibles (con parámetros para ajustarse) son fáciles de calcular pero pueden producir subajuste (alto sesgo).\nLos modelos flexibles pueden producir sobreajuste."
  },
  {
    "objectID": "apuntes/clase-03.html#clasificación",
    "href": "apuntes/clase-03.html#clasificación",
    "title": "Apuntes de clase",
    "section": "Clasificación",
    "text": "Clasificación\n\n¿Qué es clasificación?\n\nModelo politómico: Cuando la variable respuesta cuenta con más de dos categorías.\nCuando el objetivo es predecir, no suele tomarse en cuenta la jerarquía (en caso exista) entre las categorías de la variable respuesta. Por ejemplo, en caso \\(Y\\) sea una variable ordinal.\nUsualmente construimos modelos que predigan las probabilidades de categorías, dadas ciertas covariables \\(X\\).\nNo siempre los modelos de clasificación te danla clase y probabilidad de pertenencia a la clase. Los modelos por lo general dan solo la probabilidad de pertenencia a las clases. Por ejemplo:\n\nRegresión logística solo te da la probabilidad de pertenencia a la clase. Sin mbargo, ni en el caso binario basta la regla “probabilidad mayor de 50%” para asignar una clase a una nueva observación.\nÁrboles de decisión te da la clase, pero no la probabilidad de pertenencia.\n\n\n\n\nConfiguración de la clasifiación general\n\nContexto:\n\nLa variable respuesta cuenta con una cantidad finita de valores posibles … categorías.\nLa variable respuesta \\(Y\\) es cualitativa.\n\nObjetivo:\n\nConstruir un clasificador que asigne una etiqueta de clasificación a una observación futura sin etiquetar, además de evaluar la incertidumbre en esta clasificación.\n\nMedidas de rendimiento\n\nLa más popular es la tasa de error de clasificación érronea (versión de entrenamiento y prueba).\n\nPérdida 0/1:\n\nLas clasificaciones erróneas reciben la pérdida 1; y las clasificaciones correctas, pérdida 0.\nNo se emplea pérdida cuadrática para la clasificación.\n\n\n\n\nMétodos Estadísticos Tradicionales para Clasificación\n\nTres métodos comúnmente usados para clasificación:\n\nRegresión Logística\nAnálisis Discrimante Lineal (LDA)\nAnálisis Discrimante Cuadrático (QDA)\n\n\n\n\n\n\n\nGeneralized Linear Models\n\n\n\n\n\n\n\n\n\nGeneralized Linear Models\n\n\n\n\n\nLa exponential family es una familia de distribuciones, tales como la Normal, Gamma, Binomial, etc.\nLa función \\(g\\) se denomina función de enlace y debe satisfacer tener inversa, \\(g^{-1}\\), la cual se denomina función de respuesta.\n\n\n\nPredicción con el modelo logit\n\nSe denomina modelo logit al modelo de regresión logística binaria.\nEs un modelo ideal para interpretar.\nNo es un modelo ideal para predecir, en especial si se tienen clases desbalanceadas.\nRecuerde que desbalanceado no implica difícil de predecir. Además, clases desbalanceadas no es un problema de los datos.\nPredicción\n\n\\(\\hat{p}_i = \\dfrac{1}{1 + e^{-\\eta_i}}\\) = \\(\\dfrac{1}{1 + e^{-\\left( \\hat{\\beta}_0 + \\hat{\\beta}_ 1 x_{1i} + \\dots + \\hat{\\beta}_p x_{pi}\\right)}}\\)\n\\[\n  \\begin{equation}\n    \\hat{Y}_i =\n    \\begin{cases*}\n1 & si $\\hat{p}_i \\geq c$ \\\\\n0 & si $\\hat{p}_i &lt; c$\n    \\end{cases*}\n  \\end{equation}\n  \\] donde \\(c\\) se denomina punto de corte (umbral).\nUsualmente se utiliza \\(c = 0.50\\) .\n\n\n\nTheorem 2 Se puede demostrar (es complicado) que con la elección de umbral \\(c = 0.50\\) se minimiza el error de clasificación; además de ser el único umbral que minimiza tal error.\n\n\n\n¿Regresión lineal para una clasificación binaria?\n\nLa regresión lineal puede producir probabilidades menores que cero o mayores que uno.\n\n\n\nRegresión logística binaria\n\nLa response presenta solo dos categorías posibles.\nSe modela entonces \\(Y_i \\sim Bernoulli(p_i)\\) .\nObjetivo: Estimar \\(p_i = P\\left( Y_i = 1 \\mid X_1, \\dots, X_p \\right)\\)"
  },
  {
    "objectID": "apuntes/clase-04.html#uwu",
    "href": "apuntes/clase-04.html#uwu",
    "title": "Apuntes de clase",
    "section": "uwu",
    "text": "uwu"
  },
  {
    "objectID": "apuntes/clase-04.html#ejemplo-1",
    "href": "apuntes/clase-04.html#ejemplo-1",
    "title": "Apuntes de clase",
    "section": "Ejemplo 1",
    "text": "Ejemplo 1\n\nlibrary(ISLR2)\n\nWarning: package 'ISLR2' was built under R version 4.1.3\n\ndata(Default)\n\n# Default$default &lt;- as.numeric(Default$default) - 1\nglm_default &lt;- glm(default ~ balance, data = Default, family = 'binomial')\n\nsummary(glm_default)$coef\n\n                 Estimate   Std. Error   z value      Pr(&gt;|z|)\n(Intercept) -10.651330614 0.3611573721 -29.49221 3.623124e-191\nbalance       0.005498917 0.0002203702  24.95309 1.976602e-137"
  },
  {
    "objectID": "apuntes/clase-04.html#ejemplo-práctico",
    "href": "apuntes/clase-04.html#ejemplo-práctico",
    "title": "Apuntes de clase",
    "section": "Ejemplo práctico",
    "text": "Ejemplo práctico\n\nlibrary(ISLR2)\n\nWarning: package 'ISLR2' was built under R version 4.1.3\n\ndata(Default)\n\n# Default$default &lt;- as.numeric(Default$default) - 1\nglm_default &lt;- glm(\n  default ~ balance, \n  data = Default, family = 'binomial'\n)\n\nsummary(glm_default)$coef\n\n                 Estimate   Std. Error   z value      Pr(&gt;|z|)\n(Intercept) -10.651330614 0.3611573721 -29.49221 3.623124e-191\nbalance       0.005498917 0.0002203702  24.95309 1.976602e-137\n\n\n\\[\n  \\log \\left( \\dfrac{\\hat{p}_i}{1- \\hat{p}_i} \\right)  = \\hat{n}_i = -10.6513 + 0.0055*\\text{balance}_i\n\\]\n\nglm_default_2 &lt;- glm(\n  default ~ balance + income + student, \n  data = Default, family = 'binomial'\n)\n\neta &lt;- summary(glm_default_2)$coef[,1] %*% c(1, 2000, 40000, 1)\n1 / (1 + exp(-eta))\n\n          [,1]\n[1,] 0.5196218"
  },
  {
    "objectID": "apuntes/clase-04.html#clasificador-de-bayes",
    "href": "apuntes/clase-04.html#clasificador-de-bayes",
    "title": "Apuntes de clase",
    "section": "Clasificador de Bayes",
    "text": "Clasificador de Bayes\n\nEl clasificador de Bayes asigna una observación a la clase más probable, dado los valores de los predictores.\n\n\nPropiedades\n\nTiene la tasa de error de prueba más pequeña.\nPor lo general, no conocemos la verdadera distribución condicional \\(Pr(Y| X)\\) para datos reales.\nFunción pérdida: A las clasificaciones erróneas se les asigna la pérdida \\(1\\); y, a las clasificaciones correctas, \\(0\\) . Esta es conocida como pérdida-0/1.\n\n\n\nTasas de error\n\nTasa de error de entrenamiento:\n\n\\[\n\\dfrac{1}{n} \\sum_{i=1}^{n}I\\left( y_i \\ne \\hat{y}_i \\right)\n\\]\n\nTasa de error de prueba:\n\n\\[\nAverage \\left( I \\left( y_i \\ne \\hat{y}_i \\right) \\right)\n\\]\n\nSuponemos que un buen clasificador es aquel que tiene un error de prueba bajo."
  },
  {
    "objectID": "apuntes/clase-04.html#dos-paradigmas",
    "href": "apuntes/clase-04.html#dos-paradigmas",
    "title": "Apuntes de clase",
    "section": "Dos paradigmas",
    "text": "Dos paradigmas\n\nParadigma de diagnóstico:\n\nSe estima directamente la distribución a posteriori para las clases: \\(Pr(Y = k \\mid X = x)\\)\nEjemplos: Regresión logística, Clasificación KNN\n\nParadigma de muestreo:\n\nEnfoque indirecto:\n\nModele la distribución condicional de predictores, para cada clase: \\(f_k (x) = Pr(X = x \\mid Y = k)\\)\nConsidere las probabilidades a priori: \\(\\pi_k = Pr(Y = k)\\)\n\nClasificar en la clase con el producto máximo \\(pi_k f_k (x)\\)\n¿Cómo obtenemos \\(Pr(Y 0= k \\mid X = x_0)\\)?\nTeorema de Bayes: \\[\np_k (X) = Pr(Y = k \\mid X = x) =\n\\dfrac{Pr(X = x \\cap Y = k)}{f(x)} =\n\\dfrac{f_k (x) \\pi_k}{\\sum_{l=1}^{k}f_l (x) \\pi_l}\n  \\]\n\n\n\nProposition 1 No es recomendable usar los mismos datos de test para comparar modelos. Esto puesto que un modelo podría presentar menor test-error que otro, para un mismo test dataset, debido al azar."
  },
  {
    "objectID": "apuntes/clase-04.html#análisis-discriminante",
    "href": "apuntes/clase-04.html#análisis-discriminante",
    "title": "Apuntes de clase",
    "section": "Análisis Discriminante",
    "text": "Análisis Discriminante\n\nEl enfoque es modelar la distribución de \\(X\\) en cada una de las clases por separado, y, luego usar el teorema de Bayes para obtener \\(Pr(Y \\mid X)\\)."
  },
  {
    "objectID": "apuntes/clase-04.html#ejemplo-práctico-1",
    "href": "apuntes/clase-04.html#ejemplo-práctico-1",
    "title": "Apuntes de clase",
    "section": "Ejemplo práctico",
    "text": "Ejemplo práctico\n\nrda(class ~., data = diabetes)\n\nCall: \nrda(formula = class ~ ., data = diabetes)\n\nRegularization parameters: \n       gamma       lambda \n6.350887e-04 6.026917e-10 \n\nPrior probabilities of groups: \nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nMisclassification rate: \n       apparent: 6.087 %\ncross-validated: 7.725 %\n\nrda1 = rda(class ~., data = diabetes)\nrda1 \n\nCall: \nrda(formula = class ~ ., data = diabetes)\n\nRegularization parameters: \n       gamma       lambda \n1.942273e-05 3.392599e-01 \n\nPrior probabilities of groups: \nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nMisclassification rate: \n       apparent: 9.565 %\ncross-validated: 12.828 %\n\n# Predicción (entrenamiento)\nprda1 = predict(rda1, diabetes[-4])$class\n\n# Matriz de confusion (entrenamiento)\ncaret::confusionMatrix(prda1, diabetes$class)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       21      1     3\n  normal          5     65     2\n  overt           0      0    18\n\nOverall Statistics\n                                          \n               Accuracy : 0.9043          \n                 95% CI : (0.8353, 0.9513)\n    No Information Rate : 0.5739          \n    P-Value [Acc &gt; NIR] : 5.776e-15       \n                                          \n                  Kappa : 0.8293          \n                                          \n Mcnemar's Test P-Value : 0.05343         \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8077        0.9848       0.7826\nSpecificity                   0.9551        0.8571       1.0000\nPos Pred Value                0.8400        0.9028       1.0000\nNeg Pred Value                0.9444        0.9767       0.9485\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1826        0.5652       0.1565\nDetection Prevalence          0.2174        0.6261       0.1565\nBalanced Accuracy             0.8814        0.9210       0.8913\n\n# Error (entrenamiento)\nerror1 = mean(prda1 != diabetes$class)\nerror1\n\n[1] 0.09565217\n\n\n\nSelección de variables\n\n# Selección de Variables (validación cruzada)\nstepclass(\n  diabetes[,-4], diabetes$class,\n  method = \"rda\", criterion = \"AC\",\n  improvement = 0.03\n)\n\n `stepwise classification', using 10-fold cross-validated accuracy of method rda'.\n\n\n115 observations of 3 variables in 3 classes; direction: both\n\n\nstop criterion: improvement less than 3%.\n\n\naccuracy: 0.81469;  in: \"insulin\";  variables (1): insulin \naccuracy: 0.85865;  in: \"glucose\";  variables (2): insulin, glucose \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00       17.97 \n\n\nmethod      : rda \nfinal model : diabetes$class ~ glucose + insulin\n&lt;environment: 0x00000000246baea8&gt;\n\naccuracy = 0.8587 \n\n\n\n\nModelo final\n\nrda2 = rda(class ~ glucose + insulin, data = diabetes)\nrda2\n\nCall: \nrda(formula = class ~ glucose + insulin, data = diabetes)\n\nRegularization parameters: \n     gamma     lambda \n0.96120286 0.06374861 \n\nPrior probabilities of groups: \nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nMisclassification rate: \n       apparent: 6.087 %\ncross-validated: 7.101 %\n\n# Predicción\nprda2 = predict(rda2, diabetes[-4])$class\n# Matriz de confusion\ncaret::confusionMatrix(prda2, diabetes$class)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       23      0     4\n  normal          3     66     0\n  overt           0      0    19\n\nOverall Statistics\n                                          \n               Accuracy : 0.9391          \n                 95% CI : (0.8786, 0.9752)\n    No Information Rate : 0.5739          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.8931          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8846        1.0000       0.8261\nSpecificity                   0.9551        0.9388       1.0000\nPos Pred Value                0.8519        0.9565       1.0000\nNeg Pred Value                0.9659        1.0000       0.9583\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.2000        0.5739       0.1652\nDetection Prevalence          0.2348        0.6000       0.1652\nBalanced Accuracy             0.9198        0.9694       0.9130\n\n# Error\nerror1 = mean(prda2 != diabetes$class)\nerror1\n\n[1] 0.06086957\n\n# Evaluación en el conjunto de test\npredrda = predict(rda2, diabetes_test)$class\ncaret::confusionMatrix(diabetes_test$class, predrda)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical        7      2     1\n  normal          0     10     0\n  overt           0      0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.9             \n                 95% CI : (0.7347, 0.9789)\n    No Information Rate : 0.4             \n    P-Value [Acc &gt; NIR] : 1.698e-08       \n                                          \n                  Kappa : 0.85            \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   1.0000        0.8333       0.9091\nSpecificity                   0.8696        1.0000       1.0000\nPos Pred Value                0.7000        1.0000       1.0000\nNeg Pred Value                1.0000        0.9000       0.9500\nPrevalence                    0.2333        0.4000       0.3667\nDetection Rate                0.2333        0.3333       0.3333\nDetection Prevalence          0.3333        0.3333       0.3333\nBalanced Accuracy             0.9348        0.9167       0.9545"
  },
  {
    "objectID": "apuntes/clase-04.html#ejemplo-práctico-lda",
    "href": "apuntes/clase-04.html#ejemplo-práctico-lda",
    "title": "Apuntes de clase",
    "section": "Ejemplo práctico LDA",
    "text": "Ejemplo práctico LDA\n\ndiabetes = read.csv(\n  \"../datos/DiabetesTrain.csv\",\n  stringsAsFactors = TRUE\n)\n\nhead(diabetes)\n\n  glucose insulin sspg  class\n1      97     289  117 normal\n2     105     319  143 normal\n3      90     356  199 normal\n4      90     323  240 normal\n5      86     381  157 normal\n6     100     350  221 normal\n\n\n\nAnálisis descriptivo\n\nlibrary(psych)\n\ndescribeBy(diabetes[,-4], diabetes$class)\n\n\n Descriptive statistics by group \ngroup: chemical\n        vars  n   mean     sd median trimmed    mad min max range skew kurtosis\nglucose    1 26  99.46   8.81   98.5   99.32   9.64  85 114    29 0.24    -1.28\ninsulin    2 26 504.12  60.06  497.5  500.77  63.75 423 643   220 0.37    -0.89\nsspg       3 26 291.77 177.65  222.5  272.14 120.83 109 748   639 1.08    -0.01\n           se\nglucose  1.73\ninsulin 11.78\nsspg    34.84\n------------------------------------------------------------ \ngroup: normal\n        vars  n   mean    sd median trimmed   mad min max range  skew kurtosis\nglucose    1 66  91.98  8.16   91.5   92.00  8.15  70 112    42 -0.05     0.10\ninsulin    2 66 351.21 37.70  354.5  351.46 46.70 269 426   157 -0.09    -0.93\nsspg       3 66 169.02 65.49  156.5  163.39 51.89  73 490   417  1.86     6.76\n          se\nglucose 1.00\ninsulin 4.64\nsspg    8.06\n------------------------------------------------------------ \ngroup: overt\n        vars  n    mean     sd median trimmed    mad min  max range skew\nglucose    1 23  207.17  71.84    203  202.79  96.37 120  339   219 0.35\ninsulin    2 23 1002.96 315.85    972  998.21 382.51 538 1520   982 0.16\nsspg       3 23  112.61 106.57     87   94.37  65.23  10  460   450 1.72\n        kurtosis    se\nglucose    -1.28 14.98\ninsulin    -1.34 65.86\nsspg        2.72 22.22\n\npairs.panels(\n  diabetes[,1:3],\n  bg = c(\"red\",\"yellow\",\"blue\")[diabetes$class],\n  pch = 21\n)\n\n\n\npar(mfrow = c(2,2))\nboxplot(glucose ~ class, data = diabetes, main = \"glucose\")\nboxplot(insulin ~ class, data = diabetes, main = \"insulin\")\nboxplot(sspg ~ class, data = diabetes, main = \"sspg\")\npar(mfrow = c(1,1))\n\n\n\n\n\n\nAnálisis Discriminante Lineal\n\n# Estimación\nlibrary(MASS)\n\nWarning: package 'MASS' was built under R version 4.1.3\n\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:ISLR2':\n\n    Boston\n\nlda1 = lda(class ~., data = diabetes)\nlda1\n\nCall:\nlda(class ~ ., data = diabetes)\n\nPrior probabilities of groups:\nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nGroup means:\n           glucose   insulin     sspg\nchemical  99.46154  504.1154 291.7692\nnormal    91.98485  351.2121 169.0152\novert    207.17391 1002.9565 112.6087\n\nCoefficients of linear discriminants:\n                 LD1          LD2\nglucose -0.035130542 -0.056150421\ninsulin  0.013748266  0.009876402\nsspg     0.001344232  0.005489825\n\nProportion of trace:\n   LD1    LD2 \n0.8526 0.1474 \n\n# Predicción\nplda1 = predict(lda1, diabetes)$class\n\n# Matriz de confusion (entrenamiento)\ntable(plda1, diabetes$class)\n\n          \nplda1      chemical normal overt\n  chemical       19      1     5\n  normal          7     65     2\n  overt           0      0    16\n\n# Error (entrenamiento)\nerror1 = mean(plda1 != diabetes$class)\nerror1\n\n[1] 0.1304348\n\ncaret::confusionMatrix(\n  data = plda1, reference = diabetes$class\n)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       19      1     5\n  normal          7     65     2\n  overt           0      0    16\n\nOverall Statistics\n                                         \n               Accuracy : 0.8696         \n                 95% CI : (0.794, 0.9251)\n    No Information Rate : 0.5739         \n    P-Value [Acc &gt; NIR] : 6.334e-12      \n                                         \n                  Kappa : 0.7644         \n                                         \n Mcnemar's Test P-Value : 0.009308       \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.7308        0.9848       0.6957\nSpecificity                   0.9326        0.8163       1.0000\nPos Pred Value                0.7600        0.8784       1.0000\nNeg Pred Value                0.9222        0.9756       0.9293\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1652        0.5652       0.1391\nDetection Prevalence          0.2174        0.6435       0.1391\nBalanced Accuracy             0.8317        0.9006       0.8478\n\n\n\n\nSelección de Variables\n\nlibrary(klaR)\n\nWarning: package 'klaR' was built under R version 4.1.3\n\ngreedy.wilks(class ~., data = diabetes)\n\nFormula containing included variables: \n\nclass ~ insulin + glucose + sspg\n&lt;environment: 0x000000002e63c008&gt;\n\n\nValues calculated in each step of the selection procedure: \n\n     vars Wilks.lambda F.statistics.overall p.value.overall F.statistics.diff\n1 insulin    0.2469409            170.77488    9.665240e-35        170.774879\n2 glucose    0.1532280             86.28294    4.190502e-44         33.943348\n3    sspg    0.1311418             64.58470    7.641367e-46          9.262795\n  p.value.diff\n1 9.665240e-35\n2 2.994049e-12\n3 1.904104e-04\n\n# Validación Cruzada\nset.seed(666)\nstepclass(\n  diabetes[,-4], diabetes$class, \n  method = \"lda\", criterion = \"AC\",\n  # Consideramos una mejora significativa \n  # como de 10%, pero esta es una elección arbitraria\n  improvement = 0.10\n)\n\n `stepwise classification', using 10-fold cross-validated accuracy of method lda'.\n\n\n115 observations of 3 variables in 3 classes; direction: both\n\n\nstop criterion: improvement less than 10%.\n\n\naccuracy: 0.49254;  in: \"insulin\";  variables (1): insulin \naccuracy: 0.7221;  in: \"glucose\";  variables (2): insulin, glucose \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00        0.38 \n\n\nmethod      : lda \nfinal model : diabetes$class ~ glucose + insulin\n&lt;environment: 0x000000002ede17a0&gt;\n\naccuracy = 0.7221 \n\n\n\n\nEstimación\n\nlda2 = lda(class ~ glucose + insulin, data = diabetes)\n\n# Predicción (entrenamiento)\nplda2 = predict(lda2, diabetes[-4])$class\n\n# Matriz de confusion (entrenamiento)\ncaret::confusionMatrix(plda2, diabetes$class)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       23      3     4\n  normal          3     63     3\n  overt           0      0    16\n\nOverall Statistics\n                                          \n               Accuracy : 0.887           \n                 95% CI : (0.8145, 0.9384)\n    No Information Rate : 0.5739          \n    P-Value [Acc &gt; NIR] : 2.26e-13        \n                                          \n                  Kappa : 0.8013          \n                                          \n Mcnemar's Test P-Value : 0.0719          \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8846        0.9545       0.6957\nSpecificity                   0.9213        0.8776       1.0000\nPos Pred Value                0.7667        0.9130       1.0000\nNeg Pred Value                0.9647        0.9348       0.9293\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.2000        0.5478       0.1391\nDetection Prevalence          0.2609        0.6000       0.1391\nBalanced Accuracy             0.9030        0.9160       0.8478\n\n# Error\nerror2 = mean(plda2 != diabetes$class)\nerror2\n\n[1] 0.1130435\n\npartimat(\n  class ~., data = diabetes, \n  method = \"lda\", nplots.vert = 2\n)\n\n\n\n\n\n\nDatos de Test\n\ndiabetes_test = read.csv(\n  \"../datos/DiabetesTest.csv\", stringsAsFactors = TRUE\n)\nhead(diabetes_test)\n\n  glucose insulin sspg    class\n1      89     472  162 chemical\n2      96     465  237 chemical\n3     112     503  408 chemical\n4     110     477  124 chemical\n5      90     413  344 chemical\n6     102     472  297 chemical\n\n\n\n# Evaluación en el conjunto de test\npredlda = predict(lda2, diabetes_test)$class\ncaret::confusionMatrix(predlda, diabetes_test$class)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical        3      1     0\n  normal          7      9     0\n  overt           0      0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.7333          \n                 95% CI : (0.5411, 0.8772)\n    No Information Rate : 0.3333          \n    P-Value [Acc &gt; NIR] : 8.752e-06       \n                                          \n                  Kappa : 0.6             \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.3000        0.9000       1.0000\nSpecificity                   0.9500        0.6500       1.0000\nPos Pred Value                0.7500        0.5625       1.0000\nNeg Pred Value                0.7308        0.9286       1.0000\nPrevalence                    0.3333        0.3333       0.3333\nDetection Rate                0.1000        0.3000       0.3333\nDetection Prevalence          0.1333        0.5333       0.3333\nBalanced Accuracy             0.6250        0.7750       1.0000"
  },
  {
    "objectID": "apuntes/clase-04.html#ejemplo-práctico-qda",
    "href": "apuntes/clase-04.html#ejemplo-práctico-qda",
    "title": "Apuntes de clase",
    "section": "Ejemplo práctico QDA",
    "text": "Ejemplo práctico QDA\n\n# Estimación\nqda1 = qda(class ~., data = diabetes)\n\n# Predicción\npqda1 = predict(qda1, diabetes[-4])$class\n\n# Matriz de confusion (entrenamiento)\ncaret::confusionMatrix(pqda1, diabetes$class)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       22      1     2\n  normal          3     65     0\n  overt           1      0    21\n\nOverall Statistics\n                                          \n               Accuracy : 0.9391          \n                 95% CI : (0.8786, 0.9752)\n    No Information Rate : 0.5739          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.8938          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8462        0.9848       0.9130\nSpecificity                   0.9663        0.9388       0.9891\nPos Pred Value                0.8800        0.9559       0.9545\nNeg Pred Value                0.9556        0.9787       0.9785\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1913        0.5652       0.1826\nDetection Prevalence          0.2174        0.5913       0.1913\nBalanced Accuracy             0.9062        0.9618       0.9511\n\n# Error (entrenamiento)\nerror1 = mean(pqda1 != diabetes$class)\nerror1\n\n[1] 0.06086957\n\n\n\nSelección de variables\n\nset.seed(666)\nstepclass(\n  diabetes[,-4], diabetes$class,\n  method = \"qda\", criterion = \"AC\",\n  improvement = 0.03\n)\n\n `stepwise classification', using 10-fold cross-validated accuracy of method qda'.\n\n\n115 observations of 3 variables in 3 classes; direction: both\n\n\nstop criterion: improvement less than 3%.\n\n\naccuracy: 0.82819;  in: \"insulin\";  variables (1): insulin \naccuracy: 0.86379;  in: \"glucose\";  variables (2): insulin, glucose \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00        0.25 \n\n\nmethod      : qda \nfinal model : diabetes$class ~ glucose + insulin\n&lt;environment: 0x0000000027e19278&gt;\n\naccuracy = 0.8638 \n\n\n\n# Estimación\nqda2 = qda(class ~ glucose + insulin, data = diabetes)\n\n# Predicción (entrenamiento)\npqda2 = predict(qda2, diabetes[-4])$class\n\n# Matriz de confusion\ncaret::confusionMatrix(pqda2, diabetes$class)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       25      1     1\n  normal          1     65     0\n  overt           0      0    22\n\nOverall Statistics\n                                          \n               Accuracy : 0.9739          \n                 95% CI : (0.9257, 0.9946)\n    No Information Rate : 0.5739          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.955           \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.9615        0.9848       0.9565\nSpecificity                   0.9775        0.9796       1.0000\nPos Pred Value                0.9259        0.9848       1.0000\nNeg Pred Value                0.9886        0.9796       0.9892\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.2174        0.5652       0.1913\nDetection Prevalence          0.2348        0.5739       0.1913\nBalanced Accuracy             0.9695        0.9822       0.9783\n\n# Error (entrenamiento)\nerror1 = mean(pqda2 != diabetes$class)\nerror1\n\n[1] 0.02608696\n\npartimat(\n  class ~.,data = diabetes, \n  method=\"qda\", nplots.vert=2\n)\n\n\n\n\n\n\nEvaluación\n\n# Evaluación en el conjunto de test\npredqda = predict(qda2, diabetes_test)$class\ncaret::confusionMatrix(predqda, diabetes_test$class)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical        7      0     0\n  normal          2     10     0\n  overt           1      0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.9             \n                 95% CI : (0.7347, 0.9789)\n    No Information Rate : 0.3333          \n    P-Value [Acc &gt; NIR] : 1.665e-10       \n                                          \n                  Kappa : 0.85            \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.7000        1.0000       1.0000\nSpecificity                   1.0000        0.9000       0.9500\nPos Pred Value                1.0000        0.8333       0.9091\nNeg Pred Value                0.8696        1.0000       1.0000\nPrevalence                    0.3333        0.3333       0.3333\nDetection Rate                0.2333        0.3333       0.3333\nDetection Prevalence          0.2333        0.4000       0.3667\nBalanced Accuracy             0.8500        0.9500       0.9750"
  },
  {
    "objectID": "apuntes/clase-04.html#análisis-discriminante-regularizado",
    "href": "apuntes/clase-04.html#análisis-discriminante-regularizado",
    "title": "Apuntes de clase",
    "section": "Análisis Discriminante Regularizado",
    "text": "Análisis Discriminante Regularizado"
  },
  {
    "objectID": "apuntes/clase-04.html#naive-bayes",
    "href": "apuntes/clase-04.html#naive-bayes",
    "title": "Apuntes de clase",
    "section": "Naive Bayes",
    "text": "Naive Bayes\n\nMétodo popular cuando se tiene una gran cantidad de predictores.\nSuponemos que en cada clase, los predictores son independientes, (supuesto de independencia condicional dentro de clases).\nEs un método escalable, es decir, no pierde eficiencia cuando se aumenta la cantidad de predictores (más columnas).\nRápidamente genera predicciones de clasificaciones, comparado a otros modelos.\nNo es tan útil para inferencia.\nCuando las distribuciones marginales son respecto a una un predictor numérico continuo, se supone que tal predictor sigue una distribución normal univariada."
  },
  {
    "objectID": "apuntes/clase-04.html#ejercicio",
    "href": "apuntes/clase-04.html#ejercicio",
    "title": "Apuntes de clase",
    "section": "Ejercicio",
    "text": "Ejercicio\nIr avanzando la lista 2."
  }
]