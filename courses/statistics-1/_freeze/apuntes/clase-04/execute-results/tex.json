{
  "hash": "6801918e32e652e49004a6a0acafa602",
  "result": {
    "markdown": "# Apuntes de clase {-}\n\n## Ejemplo práctico\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ISLR2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ISLR2' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\ndata(Default)\n\n# Default$default <- as.numeric(Default$default) - 1\nglm_default <- glm(\n  default ~ balance, \n  data = Default, family = 'binomial'\n)\n\nsummary(glm_default)$coef\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 Estimate   Std. Error   z value      Pr(>|z|)\n(Intercept) -10.651330614 0.3611573721 -29.49221 3.623124e-191\nbalance       0.005498917 0.0002203702  24.95309 1.976602e-137\n```\n:::\n:::\n\n\n\n$$\n  \\log \\left( \\dfrac{\\hat{p}_i}{1- \\hat{p}_i} \\right)  = \\hat{n}_i = -10.6513 + 0.0055*\\text{balance}_i\n$$ \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_default_2 <- glm(\n  default ~ balance + income + student, \n  data = Default, family = 'binomial'\n)\n\neta <- summary(glm_default_2)$coef[,1] %*% c(1, 2000, 40000, 1)\n1 / (1 + exp(-eta))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          [,1]\n[1,] 0.5196218\n```\n:::\n:::\n\n\n\n\n## Clasificador de Bayes\n\n- El clasificador de Bayes asigna una observación\na la **clase más probable**, dado los valores de los predictores.\n\n### Propiedades\n\n- Tiene la **tasa de error de prueba más pequeña**.\n\n- Por lo general, no conocemos la verdadera distribución\ncondicional $Pr(Y| X)$ para datos reales.\n\n- *Función pérdida*: A las clasificaciones erróneas\nse les asigna la pérdida $1$; y, a las clasificaciones\ncorrectas, $0$ . Esta es conocida como **pérdida-0/1**.\n\n### Tasas de error\n\n- **Tasa de error de entrenamiento**:\n\n$$\n\\dfrac{1}{n} \\sum_{i=1}^{n}I\\left( y_i \\ne \\hat{y}_i \\right)\n$$\n\n\n- **Tasa de error de prueba**:\n\n$$\nAverage \\left( I \\left( y_i \\ne \\hat{y}_i \\right) \\right)\n$$\n\n- Suponemos que un *buen clasificador* es aquel\nque tiene un *error de prueba bajo*.\n\n## Dos paradigmas\n\n- **Paradigma de diagnóstico:**\n    - Se estima **directamente** la \n    **distribución a posteriori** para las clases:\n    $Pr(Y = k \\mid X = x)$ \n    - Ejemplos: Regresión logística, Clasificación KNN\n\n- **Paradigma de muestreo**:\n    - Enfoque **indirecto**:\n        - Modele la distribución condicional de predictores,\n        para cada clase: $f_k (x) = Pr(X = x \\mid Y = k)$ \n        - Considere las **probabilidades a priori**:\n        $\\pi_k = Pr(Y = k)$ \n    - Clasificar en la clase con el producto máximo $pi_k f_k (x)$ \n\n    - ¿Cómo obtenemos $Pr(Y 0= k \\mid X = x_0)$? \\\n    **Teorema de Bayes:**\n    $$\n      p_k (X) = Pr(Y = k \\mid X = x) = \n      \\dfrac{Pr(X = x \\cap Y = k)}{f(x)} =\n      \\dfrac{f_k (x) \\pi_k}{\\sum_{l=1}^{k}f_l (x) \\pi_l}\n    $$\n    \n\n::: {#prp-}\n\nNo es recomendable usar los mismos datos de test\npara comparar modelos. Esto puesto que un modelo\npodría presentar menor test-error que otro,\npara un mismo test dataset, debido al azar.\n\n:::\n\n## Análisis Discriminante\n\n- El enfoque es modelar la distribución de $X$ \nen cada una de las clases por separado, y, \nluego usar el teorema de Bayes para obtener\n$Pr(Y \\mid X)$.\n\n## Ejemplo práctico LDA\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes = read.csv(\n  \"../datos/DiabetesTrain.csv\",\n  stringsAsFactors = TRUE\n)\n\nhead(diabetes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  glucose insulin sspg  class\n1      97     289  117 normal\n2     105     319  143 normal\n3      90     356  199 normal\n4      90     323  240 normal\n5      86     381  157 normal\n6     100     350  221 normal\n```\n:::\n:::\n\n\n\n### Análisis descriptivo\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\n\ndescribeBy(diabetes[,-4], diabetes$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Descriptive statistics by group \ngroup: chemical\n        vars  n   mean     sd median trimmed    mad min max range skew kurtosis\nglucose    1 26  99.46   8.81   98.5   99.32   9.64  85 114    29 0.24    -1.28\ninsulin    2 26 504.12  60.06  497.5  500.77  63.75 423 643   220 0.37    -0.89\nsspg       3 26 291.77 177.65  222.5  272.14 120.83 109 748   639 1.08    -0.01\n           se\nglucose  1.73\ninsulin 11.78\nsspg    34.84\n------------------------------------------------------------ \ngroup: normal\n        vars  n   mean    sd median trimmed   mad min max range  skew kurtosis\nglucose    1 66  91.98  8.16   91.5   92.00  8.15  70 112    42 -0.05     0.10\ninsulin    2 66 351.21 37.70  354.5  351.46 46.70 269 426   157 -0.09    -0.93\nsspg       3 66 169.02 65.49  156.5  163.39 51.89  73 490   417  1.86     6.76\n          se\nglucose 1.00\ninsulin 4.64\nsspg    8.06\n------------------------------------------------------------ \ngroup: overt\n        vars  n    mean     sd median trimmed    mad min  max range skew\nglucose    1 23  207.17  71.84    203  202.79  96.37 120  339   219 0.35\ninsulin    2 23 1002.96 315.85    972  998.21 382.51 538 1520   982 0.16\nsspg       3 23  112.61 106.57     87   94.37  65.23  10  460   450 1.72\n        kurtosis    se\nglucose    -1.28 14.98\ninsulin    -1.34 65.86\nsspg        2.72 22.22\n```\n:::\n\n```{.r .cell-code}\npairs.panels(\n  diabetes[,1:3],\n  bg = c(\"red\",\"yellow\",\"blue\")[diabetes$class],\n  pch = 21\n)\n```\n\n::: {.cell-output-display}\n![](clase-04_files/figure-pdf/unnamed-chunk-4-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\npar(mfrow = c(2,2))\nboxplot(glucose ~ class, data = diabetes, main = \"glucose\")\nboxplot(insulin ~ class, data = diabetes, main = \"insulin\")\nboxplot(sspg ~ class, data = diabetes, main = \"sspg\")\npar(mfrow = c(1,1))\n```\n\n::: {.cell-output-display}\n![](clase-04_files/figure-pdf/unnamed-chunk-4-2.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n### Análisis Discriminante Lineal\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimación\nlibrary(MASS)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'MASS' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'MASS'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:ISLR2':\n\n    Boston\n```\n:::\n\n```{.r .cell-code}\nlda1 = lda(class ~., data = diabetes)\nlda1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nlda(class ~ ., data = diabetes)\n\nPrior probabilities of groups:\nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nGroup means:\n           glucose   insulin     sspg\nchemical  99.46154  504.1154 291.7692\nnormal    91.98485  351.2121 169.0152\novert    207.17391 1002.9565 112.6087\n\nCoefficients of linear discriminants:\n                 LD1          LD2\nglucose -0.035130542 -0.056150421\ninsulin  0.013748266  0.009876402\nsspg     0.001344232  0.005489825\n\nProportion of trace:\n   LD1    LD2 \n0.8526 0.1474 \n```\n:::\n\n```{.r .cell-code}\n# Predicción\nplda1 = predict(lda1, diabetes)$class\n\n# Matriz de confusion (entrenamiento)\ntable(plda1, diabetes$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          \nplda1      chemical normal overt\n  chemical       19      1     5\n  normal          7     65     2\n  overt           0      0    16\n```\n:::\n\n```{.r .cell-code}\n# Error (entrenamiento)\nerror1 = mean(plda1 != diabetes$class)\nerror1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1304348\n```\n:::\n\n```{.r .cell-code}\ncaret::confusionMatrix(\n  data = plda1, reference = diabetes$class\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       19      1     5\n  normal          7     65     2\n  overt           0      0    16\n\nOverall Statistics\n                                         \n               Accuracy : 0.8696         \n                 95% CI : (0.794, 0.9251)\n    No Information Rate : 0.5739         \n    P-Value [Acc > NIR] : 6.334e-12      \n                                         \n                  Kappa : 0.7644         \n                                         \n Mcnemar's Test P-Value : 0.009308       \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.7308        0.9848       0.6957\nSpecificity                   0.9326        0.8163       1.0000\nPos Pred Value                0.7600        0.8784       1.0000\nNeg Pred Value                0.9222        0.9756       0.9293\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1652        0.5652       0.1391\nDetection Prevalence          0.2174        0.6435       0.1391\nBalanced Accuracy             0.8317        0.9006       0.8478\n```\n:::\n:::\n\n\n\n### Selección de Variables \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(klaR)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'klaR' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\ngreedy.wilks(class ~., data = diabetes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFormula containing included variables: \n\nclass ~ insulin + glucose + sspg\n<environment: 0x000000001fd094a8>\n\n\nValues calculated in each step of the selection procedure: \n\n     vars Wilks.lambda F.statistics.overall p.value.overall F.statistics.diff\n1 insulin    0.2469409            170.77488    9.665240e-35        170.774879\n2 glucose    0.1532280             86.28294    4.190502e-44         33.943348\n3    sspg    0.1311418             64.58470    7.641367e-46          9.262795\n  p.value.diff\n1 9.665240e-35\n2 2.994049e-12\n3 1.904104e-04\n```\n:::\n\n```{.r .cell-code}\n# Validación Cruzada\nset.seed(666)\nstepclass(\n  diabetes[,-4], diabetes$class, \n  method = \"lda\", criterion = \"AC\",\n  # Consideramos una mejora significativa \n  # como de 10%, pero esta es una elección arbitraria\n  improvement = 0.10\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n `stepwise classification', using 10-fold cross-validated accuracy of method lda'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n115 observations of 3 variables in 3 classes; direction: both\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nstop criterion: improvement less than 10%.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\naccuracy: 0.49254;  in: \"insulin\";  variables (1): insulin \naccuracy: 0.7221;  in: \"glucose\";  variables (2): insulin, glucose \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00        0.23 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nmethod      : lda \nfinal model : diabetes$class ~ glucose + insulin\n<environment: 0x00000000219bc230>\n\naccuracy = 0.7221 \n```\n:::\n:::\n\n\n\n### Estimación\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlda2 = lda(class ~ glucose + insulin, data = diabetes)\n\n# Predicción (entrenamiento)\nplda2 = predict(lda2, diabetes[-4])$class\n\n# Matriz de confusion (entrenamiento)\ncaret::confusionMatrix(plda2, diabetes$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       23      3     4\n  normal          3     63     3\n  overt           0      0    16\n\nOverall Statistics\n                                          \n               Accuracy : 0.887           \n                 95% CI : (0.8145, 0.9384)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : 2.26e-13        \n                                          \n                  Kappa : 0.8013          \n                                          \n Mcnemar's Test P-Value : 0.0719          \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8846        0.9545       0.6957\nSpecificity                   0.9213        0.8776       1.0000\nPos Pred Value                0.7667        0.9130       1.0000\nNeg Pred Value                0.9647        0.9348       0.9293\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.2000        0.5478       0.1391\nDetection Prevalence          0.2609        0.6000       0.1391\nBalanced Accuracy             0.9030        0.9160       0.8478\n```\n:::\n\n```{.r .cell-code}\n# Error\nerror2 = mean(plda2 != diabetes$class)\nerror2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1130435\n```\n:::\n\n```{.r .cell-code}\npartimat(\n  class ~., data = diabetes, \n  method = \"lda\", nplots.vert = 2\n)\n```\n\n::: {.cell-output-display}\n![](clase-04_files/figure-pdf/unnamed-chunk-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n### Datos de Test\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes_test = read.csv(\n  \"../datos/DiabetesTest.csv\", stringsAsFactors = TRUE\n)\nhead(diabetes_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  glucose insulin sspg    class\n1      89     472  162 chemical\n2      96     465  237 chemical\n3     112     503  408 chemical\n4     110     477  124 chemical\n5      90     413  344 chemical\n6     102     472  297 chemical\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Evaluación en el conjunto de test\npredlda = predict(lda2, diabetes_test)$class\ncaret::confusionMatrix(predlda, diabetes_test$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical        3      1     0\n  normal          7      9     0\n  overt           0      0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.7333          \n                 95% CI : (0.5411, 0.8772)\n    No Information Rate : 0.3333          \n    P-Value [Acc > NIR] : 8.752e-06       \n                                          \n                  Kappa : 0.6             \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.3000        0.9000       1.0000\nSpecificity                   0.9500        0.6500       1.0000\nPos Pred Value                0.7500        0.5625       1.0000\nNeg Pred Value                0.7308        0.9286       1.0000\nPrevalence                    0.3333        0.3333       0.3333\nDetection Rate                0.1000        0.3000       0.3333\nDetection Prevalence          0.1333        0.5333       0.3333\nBalanced Accuracy             0.6250        0.7750       1.0000\n```\n:::\n:::\n\n\n\n\n## Ejemplo práctico QDA\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimación\nqda1 = qda(class ~., data = diabetes)\n\n# Predicción\npqda1 = predict(qda1, diabetes[-4])$class\n\n# Matriz de confusion (entrenamiento)\ncaret::confusionMatrix(pqda1, diabetes$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       22      1     2\n  normal          3     65     0\n  overt           1      0    21\n\nOverall Statistics\n                                          \n               Accuracy : 0.9391          \n                 95% CI : (0.8786, 0.9752)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8938          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8462        0.9848       0.9130\nSpecificity                   0.9663        0.9388       0.9891\nPos Pred Value                0.8800        0.9559       0.9545\nNeg Pred Value                0.9556        0.9787       0.9785\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1913        0.5652       0.1826\nDetection Prevalence          0.2174        0.5913       0.1913\nBalanced Accuracy             0.9062        0.9618       0.9511\n```\n:::\n\n```{.r .cell-code}\n# Error (entrenamiento)\nerror1 = mean(pqda1 != diabetes$class)\nerror1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.06086957\n```\n:::\n:::\n\n\n\n### Selección de variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(666)\nstepclass(\n  diabetes[,-4], diabetes$class,\n  method = \"qda\", criterion = \"AC\",\n  improvement = 0.03\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n `stepwise classification', using 10-fold cross-validated accuracy of method qda'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n115 observations of 3 variables in 3 classes; direction: both\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nstop criterion: improvement less than 3%.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\naccuracy: 0.82819;  in: \"insulin\";  variables (1): insulin \naccuracy: 0.86379;  in: \"glucose\";  variables (2): insulin, glucose \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00        0.27 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nmethod      : qda \nfinal model : diabetes$class ~ glucose + insulin\n<environment: 0x000000002e5694f0>\n\naccuracy = 0.8638 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Estimación\nqda2 = qda(class ~ glucose + insulin, data = diabetes)\n\n# Predicción (entrenamiento)\npqda2 = predict(qda2, diabetes[-4])$class\n\n# Matriz de confusion\ncaret::confusionMatrix(pqda2, diabetes$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       25      1     1\n  normal          1     65     0\n  overt           0      0    22\n\nOverall Statistics\n                                          \n               Accuracy : 0.9739          \n                 95% CI : (0.9257, 0.9946)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.955           \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.9615        0.9848       0.9565\nSpecificity                   0.9775        0.9796       1.0000\nPos Pred Value                0.9259        0.9848       1.0000\nNeg Pred Value                0.9886        0.9796       0.9892\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.2174        0.5652       0.1913\nDetection Prevalence          0.2348        0.5739       0.1913\nBalanced Accuracy             0.9695        0.9822       0.9783\n```\n:::\n\n```{.r .cell-code}\n# Error (entrenamiento)\nerror1 = mean(pqda2 != diabetes$class)\nerror1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02608696\n```\n:::\n\n```{.r .cell-code}\npartimat(\n  class ~.,data = diabetes, \n  method=\"qda\", nplots.vert=2\n)\n```\n\n::: {.cell-output-display}\n![](clase-04_files/figure-pdf/unnamed-chunk-12-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n### Evaluación\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Evaluación en el conjunto de test\npredqda = predict(qda2, diabetes_test)$class\ncaret::confusionMatrix(predqda, diabetes_test$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical        7      0     0\n  normal          2     10     0\n  overt           1      0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.9             \n                 95% CI : (0.7347, 0.9789)\n    No Information Rate : 0.3333          \n    P-Value [Acc > NIR] : 1.665e-10       \n                                          \n                  Kappa : 0.85            \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.7000        1.0000       1.0000\nSpecificity                   1.0000        0.9000       0.9500\nPos Pred Value                1.0000        0.8333       0.9091\nNeg Pred Value                0.8696        1.0000       1.0000\nPrevalence                    0.3333        0.3333       0.3333\nDetection Rate                0.2333        0.3333       0.3333\nDetection Prevalence          0.2333        0.4000       0.3667\nBalanced Accuracy             0.8500        0.9500       0.9750\n```\n:::\n:::\n\n\n\n\n## Análisis Discriminante Regularizado\n\n\n\n## Ejemplo práctico\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrda(class ~., data = diabetes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: \nrda(formula = class ~ ., data = diabetes)\n\nRegularization parameters: \n       gamma       lambda \n6.350887e-04 6.026917e-10 \n\nPrior probabilities of groups: \nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nMisclassification rate: \n       apparent: 6.087 %\ncross-validated: 7.725 %\n```\n:::\n\n```{.r .cell-code}\nrda1 = rda(class ~., data = diabetes)\nrda1 \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: \nrda(formula = class ~ ., data = diabetes)\n\nRegularization parameters: \n       gamma       lambda \n1.942273e-05 3.392599e-01 \n\nPrior probabilities of groups: \nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nMisclassification rate: \n       apparent: 9.565 %\ncross-validated: 12.828 %\n```\n:::\n\n```{.r .cell-code}\n# Predicción (entrenamiento)\nprda1 = predict(rda1, diabetes[-4])$class\n\n# Matriz de confusion (entrenamiento)\ncaret::confusionMatrix(prda1, diabetes$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       21      1     3\n  normal          5     65     2\n  overt           0      0    18\n\nOverall Statistics\n                                          \n               Accuracy : 0.9043          \n                 95% CI : (0.8353, 0.9513)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : 5.776e-15       \n                                          \n                  Kappa : 0.8293          \n                                          \n Mcnemar's Test P-Value : 0.05343         \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8077        0.9848       0.7826\nSpecificity                   0.9551        0.8571       1.0000\nPos Pred Value                0.8400        0.9028       1.0000\nNeg Pred Value                0.9444        0.9767       0.9485\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1826        0.5652       0.1565\nDetection Prevalence          0.2174        0.6261       0.1565\nBalanced Accuracy             0.8814        0.9210       0.8913\n```\n:::\n\n```{.r .cell-code}\n# Error (entrenamiento)\nerror1 = mean(prda1 != diabetes$class)\nerror1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.09565217\n```\n:::\n:::\n\n\n\n### Selección de variables\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Selección de Variables (validación cruzada)\nstepclass(\n  diabetes[,-4], diabetes$class,\n  method = \"rda\", criterion = \"AC\",\n  improvement = 0.03\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n `stepwise classification', using 10-fold cross-validated accuracy of method rda'.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n115 observations of 3 variables in 3 classes; direction: both\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nstop criterion: improvement less than 3%.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\naccuracy: 0.81469;  in: \"insulin\";  variables (1): insulin \naccuracy: 0.85865;  in: \"glucose\";  variables (2): insulin, glucose \n\n hr.elapsed min.elapsed sec.elapsed \n       0.00        0.00       16.91 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nmethod      : rda \nfinal model : diabetes$class ~ glucose + insulin\n<environment: 0x000000002fe87140>\n\naccuracy = 0.8587 \n```\n:::\n:::\n\n\n\n### Modelo final\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrda2 = rda(class ~ glucose + insulin, data = diabetes)\nrda2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall: \nrda(formula = class ~ glucose + insulin, data = diabetes)\n\nRegularization parameters: \n     gamma     lambda \n0.96120286 0.06374861 \n\nPrior probabilities of groups: \nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nMisclassification rate: \n       apparent: 6.087 %\ncross-validated: 7.101 %\n```\n:::\n\n```{.r .cell-code}\n# Predicción\nprda2 = predict(rda2, diabetes[-4])$class\n# Matriz de confusion\ncaret::confusionMatrix(prda2, diabetes$class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       23      0     4\n  normal          3     66     0\n  overt           0      0    19\n\nOverall Statistics\n                                          \n               Accuracy : 0.9391          \n                 95% CI : (0.8786, 0.9752)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8931          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8846        1.0000       0.8261\nSpecificity                   0.9551        0.9388       1.0000\nPos Pred Value                0.8519        0.9565       1.0000\nNeg Pred Value                0.9659        1.0000       0.9583\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.2000        0.5739       0.1652\nDetection Prevalence          0.2348        0.6000       0.1652\nBalanced Accuracy             0.9198        0.9694       0.9130\n```\n:::\n\n```{.r .cell-code}\n# Error\nerror1 = mean(prda2 != diabetes$class)\nerror1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.06086957\n```\n:::\n\n```{.r .cell-code}\n# Evaluación en el conjunto de test\npredrda = predict(rda2, diabetes_test)$class\ncaret::confusionMatrix(diabetes_test$class, predrda)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical        7      2     1\n  normal          0     10     0\n  overt           0      0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.9             \n                 95% CI : (0.7347, 0.9789)\n    No Information Rate : 0.4             \n    P-Value [Acc > NIR] : 1.698e-08       \n                                          \n                  Kappa : 0.85            \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   1.0000        0.8333       0.9091\nSpecificity                   0.8696        1.0000       1.0000\nPos Pred Value                0.7000        1.0000       1.0000\nNeg Pred Value                1.0000        0.9000       0.9500\nPrevalence                    0.2333        0.4000       0.3667\nDetection Rate                0.2333        0.3333       0.3333\nDetection Prevalence          0.3333        0.3333       0.3333\nBalanced Accuracy             0.9348        0.9167       0.9545\n```\n:::\n:::\n\n\n\n\n## Naive Bayes\n\n- Método popular cuando se tiene una **gran cantidad de predictores**.\n- Suponemos que **en cada clase, los predictores son independientes**,\n(supuesto de **independencia condicional dentro de clases**).\n- Es un **método escalable**, es decir, no pierde eficiencia cuando\nse aumenta la cantidad de predictores (más columnas).\n- **Rápidamente** genera predicciones de clasificaciones, \ncomparado a otros modelos.\n- No es tan útil para **inferencia**.\n\n- Cuando las distribuciones marginales son respecto a una\nun **predictor numérico continuo, se supone** que tal predictor\nsigue una **distribución normal univariada**.\n\n## Ejercicio\n\nIr avanzando la lista 2.",
    "supporting": [
      "clase-04_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}