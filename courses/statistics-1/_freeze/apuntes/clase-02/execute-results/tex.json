{
  "hash": "192504b3549b145fca0c2e4cf2f3d461",
  "result": {
    "markdown": "# Apuntes de clase {-}\n\n## Objetivo de Statistical Learning\n\n- Suposiciones:\n    - Se observa una **variable respuesta** *cuantitativa* $Y$ .\n    - Se cuentan con $p$ predictores $x_1, \\dots, x_n$ .\n    - Existe una función $f$ tal que $Y = f(x) + \\epsilon$ .\n    - Donde $\\epsilon$, aleatorio, es **independiente** de $X$, y tiene **media** cero.\n\n- El término $\\epsilon$ nos permite hacer **inferencia** ...\nlas predicciones tienen un *intervalo de confianza*.\n\n- **OBJETIVO**: Estimar $f$ .\n\n- Respecto a la **inferencia** posible tras estimar $f$, \nse refieren a generalizar estadísiticamente la relación entre los predictors y la response (ejemplo: analizar los coeficientes tras regresión lineal); decir si los atributos son **estadísticamente significativos**.\n\n### Motivo 1: Predicción\n\n- **Objetivo**: Predecir, con la mayor precisión posible, la respuesta $Y$, dadas nuevas observaciones $x$ de las covariables.\n\n$$\n\\hat{Y} = \\hat{f}(x)\n$$\n\n- Para predicción, **no requerimos la forma exacta de $\\hat{f}$** .\n\n- Existen dos términos que influyen en la **precisión**\nde $\\hat{Y}$, como prediccion de $\\hat{Y}$ :\n    - **Error reducible**: Proviene de nuestra estimación $\\hat{f}$ de $f$ .\n    - **Error ireducible**: Proviene del término del error $\\epsilon$ y no puede reducirse mejorando $\\hat{f}$ .\n\n- Fijada la estimación $\\hat{f}$, respeto a la respuesta $Y$ y \nun conjunto de predictores $X$, se cumple\n\n$$\nE \\left[ \\left( Y - \\hat{Y} \\right)^2\\right] =\n\\underbrace{E\\left[\\left( f(X) - \\hat{f}(X) \\right)^2\\right]}_{\\text{error reducible}}\n+ \\underbrace{\\text{var}(\\epsilon)}_{\\text{error irreducible}}\n$$\n\n### Motivo 2: Inferencia\n\n- **Objetivo**: *Comprender* cómo la variable respuesta se \nve afectada por los diversos predictores (*covariables*).\n\n- **Requerimos la forma exacta de $\\hat{f}$**:\n    - ¿Qué predictores están asociados con la respuesta?\n    - ¿Cuál es la relación entre la respuesta y cada predictor?\n    - ¿La relación puede ser lineal, o se requiere un modelo más complejo?\n\n\n## Regresión y Clasificación\n\n- **Regresión**: Cuando la variable respuesta es *numérica*.\n- **Clasificación** Cuando la variable respuesta es *categórica*.\n\n\n## Estimación de $f$ \n\n- Main idea:\n    - Usar un conjunto de **datos de entrenamiento**\n    $\\left( x_1, y_1 \\right), \\dots, \\left( x_n, y_n \\right)$ \n    para hallar una estimación $\\hat{f}$, tal que\n    $\\hat{f}(X) \\approx Y$, para cada $\\left( X, Y \\right)$ \n\n- Para **predicción**, NUNCA evaluar la estimación\n$\\hat{f}$ en una observación de entrenamiento $X$ .\n\n- Presenta dos enfoques principales: Param. y No param. .\n\n### Métodos paramétricos\n\n- Steps:\n    1. **Fijar** una forma para $f$ .\n    1 **Estimar los parámetros** desconocidos de $f$,\n    unsando el conjunto de entrenamiento.\n\n\n### Métodos no paramétricos\n\n- Buscan una estimación de $f$, sin hacer suposiciones\nexplícitas de la función $f$ .\n\n- En cierto sentido, se consideran *infinitos* parámetros.\n\n- Ejemplo: Algoritmo de los $K$-vecinos.\n\n- **Parámetro**: Constante del modelo, que se **estima**.\n- **Hiperparámetro**: Constante del modelo, que se **escoge** libremente. Por ejemplo, el valor $K$ en el algoritmo de $K$-means.\n\n- Los hiperparámetros se pueden **calibrar** para obtener un nivel\nde adecuado de flexibilidad para el modelo.\n\n### Param. vs No param.\n\n- Suelen ser de **mayor interpretabilidad**: Paramétrico.\n- Tienden a ser **más flexibles**: No paramétricos.\n- Suelen tener **mayor complejidad computacional**: No paramétricos.\n- Suele requerir una mayor cantidad de datos: No paramétricos.\n\n- No necesariamente un método no paramétrico siempre produce\npredicciones más precisas, comparado a un método paramétrico.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Comparación](../media/param-vs-no-param.jpg){width=100%}\n:::\n:::\n\n\n\n\n## Prediction accuracy vs Interpretabilidad\n\n- Métodos **inflexibles** (o *rígidos*), son aquellos que\ntienen **fuerte** restricciones sobre la forma de $f$ .\n\n- La elección de un método flexible o inflexible depende\ndel objetivo en mente:\n    - If goal is **inferencia**, then se prefiere métodos **inflexibles**\n    - If goal is **predicción**, then se prefiere métodos **flexibles**.\n\n- **Sobreajuste**: Ocurre cuando $\\hat{f}$ se ajusta \ndemasiado a los datos observados.\n- **Subajuste**: Ocurre cuando $\\hat{f}$ es demasiado rígida\npara capturar la estructura subyacente de los datos.\n\n## EJERCICIO\n\nResolver la lista 1 publicada en Paideia,\nal menos hasta el item c (no included).\n\n\n## Evaluación de la precisión del modelo\n\n- **Ningún método** domina a todos los demás sobre\ntodos conjuntos de datos posibles.\n\n### Función pérdida\n\n- Para variable respuesta numérica, las métricas\n$L1$ y $L2$ suelen usarse.\n\n- Para response categórica, se puede usar la asignación\n0 (si $\\hat{y}_i = y_i$ ); y, 1, caso contrario.\n\n- En problemas de regresión, suele emplearse la \n**pérdida cuadrática** ($L2$).\n\n### MSE de entrenamiento\n\n- Notación: $\\text{MSE}_{\\text{train}} = \\dfrac{1}{n} \\displaystyle{ \\sum_{i=1}^{n}\\left( y_i - \\hat{f}(x_i) \\right)^2}$ \n\n- Cuando se evalúa $\\hat{f}$ en una observación de entrenamiento,\nno es posible saber si la predicción fue precisa debido a que \nel modelo aprendió o porque para el modelo se empleó el valor\nobservado para la response variable (*caso modelo plagió*).\n\n### MSE de prueba\n\n- Evaluamos el modelo con una muestra de observaciones\nque no fue usada para entrenar al modelo. Esta muestra se denomina\n**datos de prueba (test)**.\n\n- Para un conjunto de $n_0$ observaciones de prueba $\\left( x_{0j}, y_{0j} \\right)$, se define:\n\n$\\text{MSE}_{\\text{test}} = \\dfrac{1}{n_0} \\displaystyle{ \\sum_{j=1}^{n_0}\\left( y_{0j} - \\hat{f}(x_{0j}) \\right)^2}$ \n",
    "supporting": [
      "clase-02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}