[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Learning 1",
    "section": "",
    "text": "Sílabo"
  },
  {
    "objectID": "apuntes/clase-01.html#sobre-el-curso",
    "href": "apuntes/clase-01.html#sobre-el-curso",
    "title": "Apuntes de clase",
    "section": "Sobre el curso",
    "text": "Sobre el curso\nCasi toda la teoría del curso está contenida en ISLR, libro principal de la bibliografía del curso.\nLas listas deben ir avanzándose, pues la entrega oficial consistirá de modificaciones sobre algunos problemas de esas listas, con solo uno o dos días de plazo para la entrega.\nSolo habrá, most likely, máximo tres tareas académicas, pero ninguna se elimina.\nLas tareas no son las que están actualmente en Paideia, pero se basarán en las listas ya subidas.\nMáximo grupos de 4 para los grupos de las tareas; aunque puede ser individual también."
  },
  {
    "objectID": "apuntes/clase-01.html#introducción",
    "href": "apuntes/clase-01.html#introducción",
    "title": "Apuntes de clase",
    "section": "Introducción",
    "text": "Introducción\n\nMain goal:\n\nPredicción (no inferencia, eso se ve en otros cursos)\nFrom dataset, saber qué algoritmo de aprendizaje estadístico escoger, además de saber comunicar los hallazgos encontrados.\n\nHay más similitudes que diferencias entre Statistical Learning y Machine Learning (Aprendizaje de Máquina).\n\n\n¿Qué es Statistical Learning?\n\nSet of tools to understand data.\nDistinción principal: Supervisado vs No Supervisado\nCadena de stat. learning.: modelo -&gt; método -&gt; algoritmo -&gt; análisis -&gt; interpretación\nObjetivos principales:\n\nPredecir: Qué va a pasar\nInferencia: Cómo va a pasar\n\nEn Estadística, es muy importante considerar de dónde vienen los datos (muestreados under some probabilistic distribution).\n\n\n\nStatistical Learning vs Data Science\nData Science también busca obtener info a partir de datos, pero siempre require una implementación. Esto pues Data Science combina diversas disciplinas (math, CS, etc) para darles un enfoque pragmático.\nEste enfoque pragmático no es necesario en Statistical Learning.\nAmbos enfoques son importantes en la sociedad."
  },
  {
    "objectID": "apuntes/clase-01.html#aprendizaje-estadístico",
    "href": "apuntes/clase-01.html#aprendizaje-estadístico",
    "title": "Apuntes de clase",
    "section": "Aprendizaje Estadístico",
    "text": "Aprendizaje Estadístico\n\n¿Qué es?\nProceso de aprendizaje a partir de los datos.\n\nA partir de la aplicación de modelos a un conjunto de entrenamiento podemos:\n\nExtraer conclusiones acerca de las relaciones entre las variables inferencia.\nEncontrar una función predictiva para nuevas observaciones predicción.\n\n\n\n\nEl problema del Aprendizaje Supervisado\n\nPunto de partida:\n\nMedición del resultado \\(Y\\) (variable dependiente/respuesta/objetivo)\nVector de \\(p\\) mediciones predictoras \\(X = (X_1, \\cdots, X_p)\\), también llamadas entradas/regresores/covariables/características o variables independientes.\nEn problemas de regresión, \\(Y\\) es cuantitativa; en problemas de clasificación, \\(Y\\) toma valores en un conjunto finito y desordenado de clases o atributos predefinidos.\nTenemos datos de entrenamiento \\((x_1, Y_1), \\cdots, (x_n, Y_n)\\).\n\nA partir del training set, nos gustaría:\n\nPredecir nuevos casos de prueba.\nComprender como se relacionan las variables.\nEvaluar la calidad de predicciones e inferencias.\n\nLa variable respuesta supervisa nuestro análisis.\n\n\n\nEl problema del Aprendizaje No Supervisado\n\nNo hay variable respuesta.\nSe buscan patrones o agrupaciones (ocultas) en los datos, para obtener información y comprensión.\nHay más subjetividad al momento de comparar modelos; por ello importa mucho más el conocimiento sobre el área de aplicación (field experts).\n\n\n\nFilosofía general\n\nLos métodos más simples a menudo funcionan tan bien como los más complicados.\n\n\n\nStatistical Learning vs Machine Learning\n\n\\(\\text{ML} \\subset \\text{AI}\\) (algoritmos)\n\\(\\text{SL} \\subset \\text{Statistics}\\) (modelos)\nPresentan un mayor enfoque en:\n\nML: Precisión de la predicción y aplicaciones a gran escala.\nSL: Modelos, su interpretabilidad, precisión e incertidumbre.\n\nMétodo escalable: Al añadir más datos o más variables, la precisión no se reduce.\nSL y ML emplean casi las mismas técnicas.\nComparado a un curso de ML, en este curso nos enfocaremos más en comprender los modelos que usaremos, cómo funcionan."
  },
  {
    "objectID": "apuntes/clase-01.html#lista-de-ejercicios",
    "href": "apuntes/clase-01.html#lista-de-ejercicios",
    "title": "Apuntes de clase",
    "section": "Lista de ejercicios",
    "text": "Lista de ejercicios\nLista 1"
  },
  {
    "objectID": "apuntes/clase-02.html#objetivo-de-statistical-learning",
    "href": "apuntes/clase-02.html#objetivo-de-statistical-learning",
    "title": "Apuntes de clase",
    "section": "Objetivo de Statistical Learning",
    "text": "Objetivo de Statistical Learning\n\nSuposiciones:\n\nSe observa una variable respuesta cuantitativa \\(Y\\) .\nSe cuentan con \\(p\\) predictores \\(x_1, \\dots, x_n\\) .\nExiste una función \\(f\\) tal que \\(Y = f(x) + \\epsilon\\) .\nDonde \\(\\epsilon\\), aleatorio, es independiente de \\(X\\), y tiene media cero.\n\nEl término \\(\\epsilon\\) nos permite hacer inferencia … las predicciones tienen un intervalo de confianza.\nOBJETIVO: Estimar \\(f\\) .\nRespecto a la inferencia posible tras estimar \\(f\\), se refieren a generalizar estadísiticamente la relación entre los predictors y la response (ejemplo: analizar los coeficientes tras regresión lineal); decir si los atributos son estadísticamente significativos.\n\n\nMotivo 1: Predicción\n\nObjetivo: Predecir, con la mayor precisión posible, la respuesta \\(Y\\), dadas nuevas observaciones \\(x\\) de las covariables.\n\n\\[\n\\hat{Y} = \\hat{f}(x)\n\\]\n\nPara predicción, no requerimos la forma exacta de \\(\\hat{f}\\) .\nExisten dos términos que influyen en la precisión de \\(\\hat{Y}\\), como prediccion de \\(\\hat{Y}\\) :\n\nError reducible: Proviene de nuestra estimación \\(\\hat{f}\\) de \\(f\\) .\nError ireducible: Proviene del término del error \\(\\epsilon\\) y no puede reducirse mejorando \\(\\hat{f}\\) .\n\nFijada la estimación \\(\\hat{f}\\), respeto a la respuesta \\(Y\\) y un conjunto de predictores \\(X\\), se cumple\n\n\\[\nE \\left[ \\left( Y - \\hat{Y} \\right)^2\\right] =\n\\underbrace{E\\left[\\left( f(X) - \\hat{f}(X) \\right)^2\\right]}_{\\text{error reducible}}\n+ \\underbrace{\\text{var}(\\epsilon)}_{\\text{error irreducible}}\n\\]\n\n\nMotivo 2: Inferencia\n\nObjetivo: Comprender cómo la variable respuesta se ve afectada por los diversos predictores (covariables).\nRequerimos la forma exacta de \\(\\hat{f}\\):\n\n¿Qué predictores están asociados con la respuesta?\n¿Cuál es la relación entre la respuesta y cada predictor?\n¿La relación puede ser lineal, o se requiere un modelo más complejo?"
  },
  {
    "objectID": "apuntes/clase-02.html#regresión-y-clasificación",
    "href": "apuntes/clase-02.html#regresión-y-clasificación",
    "title": "Apuntes de clase",
    "section": "Regresión y Clasificación",
    "text": "Regresión y Clasificación\n\nRegresión: Cuando la variable respuesta es numérica.\nClasificación Cuando la variable respuesta es categórica."
  },
  {
    "objectID": "apuntes/clase-02.html#estimación-de-f",
    "href": "apuntes/clase-02.html#estimación-de-f",
    "title": "Apuntes de clase",
    "section": "Estimación de \\(f\\)",
    "text": "Estimación de \\(f\\)\n\nMain idea:\n\nUsar un conjunto de datos de entrenamiento \\(\\left( x_1, y_1 \\right), \\dots, \\left( x_n, y_n \\right)\\) para hallar una estimación \\(\\hat{f}\\), tal que \\(\\hat{f}(X) \\approx Y\\), para cada \\(\\left( X, Y \\right)\\)\n\nPara predicción, NUNCA evaluar la estimación \\(\\hat{f}\\) en una observación de entrenamiento \\(X\\) .\nPresenta dos enfoques principales: Param. y No param. .\n\n\nMétodos paramétricos\n\nSteps:\n\nFijar una forma para \\(f\\) . 1 Estimar los parámetros desconocidos de \\(f\\), unsando el conjunto de entrenamiento.\n\n\n\n\nMétodos no paramétricos\n\nBuscan una estimación de \\(f\\), sin hacer suposiciones explícitas de la función \\(f\\) .\nEn cierto sentido, se consideran infinitos parámetros.\nEjemplo: Algoritmo de los \\(K\\)-vecinos.\nParámetro: Constante del modelo, que se estima.\nHiperparámetro: Constante del modelo, que se escoge libremente. Por ejemplo, el valor \\(K\\) en el algoritmo de \\(K\\)-means.\nLos hiperparámetros se pueden calibrar para obtener un nivel de adecuado de flexibilidad para el modelo.\n\n\n\nParam. vs No param.\n\nSuelen ser de mayor interpretabilidad: Paramétrico.\nTienden a ser más flexibles: No paramétricos.\nSuelen tener mayor complejidad computacional: No paramétricos.\nSuele requerir una mayor cantidad de datos: No paramétricos.\nNo necesariamente un método no paramétrico siempre produce predicciones más precisas, comparado a un método paramétrico.\n\n\n\n\n\n\nComparación"
  },
  {
    "objectID": "apuntes/clase-02.html#prediction-accuracy-vs-interpretabilidad",
    "href": "apuntes/clase-02.html#prediction-accuracy-vs-interpretabilidad",
    "title": "Apuntes de clase",
    "section": "Prediction accuracy vs Interpretabilidad",
    "text": "Prediction accuracy vs Interpretabilidad\n\nMétodos inflexibles (o rígidos), son aquellos que tienen fuerte restricciones sobre la forma de \\(f\\) .\nLa elección de un método flexible o inflexible depende del objetivo en mente:\n\nIf goal is inferencia, then se prefiere métodos inflexibles\nIf goal is predicción, then se prefiere métodos flexibles.\n\nSobreajuste: Ocurre cuando \\(\\hat{f}\\) se ajusta demasiado a los datos observados.\nSubajuste: Ocurre cuando \\(\\hat{f}\\) es demasiado rígida para capturar la estructura subyacente de los datos."
  },
  {
    "objectID": "apuntes/clase-02.html#ejercicio",
    "href": "apuntes/clase-02.html#ejercicio",
    "title": "Apuntes de clase",
    "section": "EJERCICIO",
    "text": "EJERCICIO\nResolver la lista 1 publicada en Paideia, al menos hasta el item c (no included)."
  },
  {
    "objectID": "apuntes/clase-02.html#evaluación-de-la-precisión-del-modelo",
    "href": "apuntes/clase-02.html#evaluación-de-la-precisión-del-modelo",
    "title": "Apuntes de clase",
    "section": "Evaluación de la precisión del modelo",
    "text": "Evaluación de la precisión del modelo\n\nNingún método domina a todos los demás sobre todos conjuntos de datos posibles.\n\n\nFunción pérdida\n\nPara variable respuesta numérica, las métricas \\(L1\\) y \\(L2\\) suelen usarse.\nPara response categórica, se puede usar la asignación 0 (si \\(\\hat{y}_i = y_i\\) ); y, 1, caso contrario.\nEn problemas de regresión, suele emplearse la pérdida cuadrática (\\(L2\\)).\n\n\n\nMSE de entrenamiento\n\nNotación: \\(\\text{MSE}_{\\text{train}} = \\dfrac{1}{n} \\displaystyle{ \\sum_{i=1}^{n}\\left( y_i - \\hat{f}(x_i) \\right)^2}\\)\nCuando se evalúa \\(\\hat{f}\\) en una observación de entrenamiento, no es posible saber si la predicción fue precisa debido a que el modelo aprendió o porque para el modelo se empleó el valor observado para la response variable (caso modelo plagió).\n\n\n\nMSE de prueba\n\nEvaluamos el modelo con una muestra de observaciones que no fue usada para entrenar al modelo. Esta muestra se denomina datos de prueba (test).\nPara un conjunto de \\(n_0\\) observaciones de prueba \\(\\left( x_{0j}, y_{0j} \\right)\\), se define:\n\n\\(\\text{MSE}_{\\text{test}} = \\dfrac{1}{n_0} \\displaystyle{ \\sum_{j=1}^{n_0}\\left( y_{0j} - \\hat{f}(x_{0j}) \\right)^2}\\)"
  },
  {
    "objectID": "apuntes/clase-03.html#bias-variance-tradeoff",
    "href": "apuntes/clase-03.html#bias-variance-tradeoff",
    "title": "Apuntes de clase",
    "section": "Bias-variance tradeoff",
    "text": "Bias-variance tradeoff\nFijando un valor \\(x_0\\) para los predictores, y considerando una familia de training datasets, cada uno de esos training sets produce una estimación \\(\\hat{f}\\) de la función \\(f\\).\nAhora, considere el siguiente resultado:\n\nTheorem 1 \\[\nE \\left[\\left( Y - \\hat{f}\\left( x_o \\right) \\right)^2\\right]\n= \\text{ Var}\\left( \\epsilon \\right) +\n\\text{ Var}\\left( \\hat{f}\\left( x_0 \\right) \\right) +\n\\left[\\text{ Bias}\\left( \\hat{f}\\left( x_0 \\right) \\right)\\right]^2\n\\]\n\nEl sesgo consiste en cómo se aleja el valor real de la variable, en comparacion con el promedio de las estimaciones.\nModelos que suelen tenor menor sesgo, suelen tener mayor varianza, y viceversa.\n\nProposition 1 Para modelos más flexibles, la varianza se incrementa y el sesgo disminuye. (not aaalways true).\n\n\nProposition 2 Resulta que el punto donde el \\(\\text{ MSE }_{test}\\) alcanza un mínimo (en el eje Y, siendo el eje X el nivel de flexibilidad), a vecese coincide con el punto donde se intersectan el bias y varianza de la estimación \\(\\hat{f}\\)\n\n\n\n\n\n\nBias-variance tradeoff\n\n\n\n\n\nResumen:\n\nA medida que aumenta la complejidad (y, por tanto la flexibilidad) de un modelo, el modelo se vuelve más adaptable a estructuras subyacentes y cae el error de entrenaminto (sobreajuste)\nEl error de prueba es el error de predicción sobre una muestra de prueba.\nLos modelos inflexibles (con parámetros para ajustarse) son fáciles de calcular pero pueden producir subajuste (alto sesgo).\nLos modelos flexibles pueden producir sobreajuste."
  },
  {
    "objectID": "apuntes/clase-03.html#clasificación",
    "href": "apuntes/clase-03.html#clasificación",
    "title": "Apuntes de clase",
    "section": "Clasificación",
    "text": "Clasificación\n\n¿Qué es clasificación?\n\nModelo politómico: Cuando la variable respuesta cuenta con más de dos categorías.\nCuando el objetivo es predecir, no suele tomarse en cuenta la jerarquía (en caso exista) entre las categorías de la variable respuesta. Por ejemplo, en caso \\(Y\\) sea una variable ordinal.\nUsualmente construimos modelos que predigan las probabilidades de categorías, dadas ciertas covariables \\(X\\).\nNo siempre los modelos de clasificación te danla clase y probabilidad de pertenencia a la clase. Los modelos por lo general dan solo la probabilidad de pertenencia a las clases. Por ejemplo:\n\nRegresión logística solo te da la probabilidad de pertenencia a la clase. Sin mbargo, ni en el caso binario basta la regla “probabilidad mayor de 50%” para asignar una clase a una nueva observación.\nÁrboles de decisión te da la clase, pero no la probabilidad de pertenencia.\n\n\n\n\nConfiguración de la clasifiación general\n\nContexto:\n\nLa variable respuesta cuenta con una cantidad finita de valores posibles … categorías.\nLa variable respuesta \\(Y\\) es cualitativa.\n\nObjetivo:\n\nConstruir un clasificador que asigne una etiqueta de clasificación a una observación futura sin etiquetar, además de evaluar la incertidumbre en esta clasificación.\n\nMedidas de rendimiento\n\nLa más popular es la tasa de error de clasificación érronea (versión de entrenamiento y prueba).\n\nPérdida 0/1:\n\nLas clasificaciones erróneas reciben la pérdida 1; y las clasificaciones correctas, pérdida 0.\nNo se emplea pérdida cuadrática para la clasificación.\n\n\n\n\nMétodos Estadísticos Tradicionales para Clasificación\n\nTres métodos comúnmente usados para clasificación:\n\nRegresión Logística\nAnálisis Discrimante Lineal (LDA)\nAnálisis Discrimante Cuadrático (QDA)\n\n\n\n\n\n\n\nGeneralized Linear Models\n\n\n\n\n\n\n\n\n\nGeneralized Linear Models\n\n\n\n\n\nLa exponential family es una familia de distribuciones, tales como la Normal, Gamma, Binomial, etc.\nLa función \\(g\\) se denomina función de enlace y debe satisfacer tener inversa, \\(g^{-1}\\), la cual se denomina función de respuesta.\n\n\n\nPredicción con el modelo logit\n\nSe denomina modelo logit al modelo de regresión logística binaria.\nEs un modelo ideal para interpretar.\nNo es un modelo ideal para predecir, en especial si se tienen clases desbalanceadas.\nRecuerde que desbalanceado no implica difícil de predecir. Además, clases desbalanceadas no es un problema de los datos.\nPredicción\n\n\\(\\hat{p}_i = \\dfrac{1}{1 + e^{-\\eta_i}}\\) = \\(\\dfrac{1}{1 + e^{-\\left( \\hat{\\beta}_0 + \\hat{\\beta}_ 1 x_{1i} + \\dots + \\hat{\\beta}_p x_{pi}\\right)}}\\)\n\\[\n  \\begin{equation}\n    \\hat{Y}_i =\n    \\begin{cases*}\n1 & si $\\hat{p}_i \\geq c$ \\\\\n0 & si $\\hat{p}_i &lt; c$\n    \\end{cases*}\n  \\end{equation}\n  \\] donde \\(c\\) se denomina punto de corte (umbral).\nUsualmente se utiliza \\(c = 0.50\\) .\n\n\n\nTheorem 2 Se puede demostrar (es complicado) que con la elección de umbral \\(c = 0.50\\) se minimiza el error de clasificación; además de ser el único umbral que minimiza tal error.\n\n\n\n¿Regresión lineal para una clasificación binaria?\n\nLa regresión lineal puede producir probabilidades menores que cero o mayores que uno.\n\n\n\nRegresión logística binaria\n\nLa response presenta solo dos categorías posibles.\nSe modela entonces \\(Y_i \\sim Bernoulli(p_i)\\) .\nObjetivo: Estimar \\(p_i = P\\left( Y_i = 1 \\mid X_1, \\dots, X_p \\right)\\)"
  }
]