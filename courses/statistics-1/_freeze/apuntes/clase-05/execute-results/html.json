{
  "hash": "e63fda07de9e57953b592b73f754fc7a",
  "result": {
    "markdown": "# Apuntes de clase {-}\n\n## Naive Bayes\n\n- Es un modelo **no paramétrico**, donde, entre sus parámetros\nestá la estimación, via frecuencia relativa, de los parámetros\n$Pr[Y=k]$ de la población.\n\n- **No es un modelo interpetable** ... no \nse usa para entender cómo afectan los predictores a la respuesta.\n\n- No nos permite conocer la verdadera distribución condicional\nde $Pr(Y\\mid X)$ para datos reales.\n\n- El supuesto de normalidad multivariada\ncasi nunca se cumple en la vida real,\npor lo que el modelo **Naive Bayes**\npropone, en parte, una \n**menor restricción sobre la distribución de los predictores**.\n\n### Cálculo de probabilidades condicionales\n\n- El clasificador Naive Bayes puede ser aplicado también\ncuando hay **predictors continuos**. Alternativas:\n    - **Discretización**.  \n    Discretizar variables numéricas **no** siempre \n    es una *pérdida de información*. Más bien, la discretización\n    puede ser una buena alternativa para **remover ruido de los datos**,\n    **lidiar con** el hecho que las variables numéricas presentan\n    **distintas escalas (min max)**.\n    \n    - [Estimación no paramétrica](https://www.researchgate.net/publication/43185083_Nonparametric_and_Semiparametric_Models) \n    de la densidad del kernel.\n\n    - Supone una distribución para cada predictora, por lo general\n    Gaussiana, con media y varianza estimada de los datos.\n\nSi simplemente asumes normalidad, es parecido (no totalmente)\nal caso estudiado en Análisis Discriminante.\n\n### Estimador Naive Bayes\n\n- Es importante **evitar** que haya alguna **probabilidad igual a cero**, respecto a alguna de las clases.\n    - En ese tipo de casos, \n    se puede usar una [correción de Laplace](https://dials.tidymodels.org/reference/Laplace.html).\n    - **No existe un corrector Laplaciano mejor que todos**, \n    pero por lo general suele usarse el valor 1.\n    - Aún así, puede tratarse el corrector Laplaciano\n    como un **hiperparámetro** del modelo.\n\n### Predicción\n\n- Para predecir la clase a la cual pertenece $X$, \n$Pr[Y = k]Pr[X \\mid Y = k]$ es evaluado para cada clase $k$ .\n\n- El clasificador predecirá que los valores de $X$ pertenecen\na la clase $i$ si y solo si:\n$$\n\\begin{gather}\n  Pr[Y = i]Pr[X \\mid Y = i] > Pr[Y = j]Pr[X \\mid Y = j], \\\\\n  \\; \\forall 1\\leq j\\leq m, \\; j \\ne i\n\\end{gather}\n$$\n\n\n## Ejemplo práctico\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes = read.csv(\n  \"../datos/DiabetesTrain.csv\", stringsAsFactors = TRUE\n)\nhead(diabetes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  glucose insulin sspg  class\n1      97     289  117 normal\n2     105     319  143 normal\n3      90     356  199 normal\n4      90     323  240 normal\n5      86     381  157 normal\n6     100     350  221 normal\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# ¿Hay normalidad?\ndiabetes$glucose |> hist()\n```\n\n::: {.cell-output-display}\n![](clase-05_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n### Sin discretizar y asumiendo normalidad\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(e1071)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'e1071' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\na <- naiveBayes(class ~ .,data = diabetes)\na\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nNaive Bayes Classifier for Discrete Predictors\n\nCall:\nnaiveBayes.default(x = X, y = Y, laplace = laplace)\n\nA-priori probabilities:\nY\nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\nConditional probabilities:\n          glucose\nY               [,1]      [,2]\n  chemical  99.46154  8.805593\n  normal    91.98485  8.164637\n  overt    207.17391 71.837982\n\n          insulin\nY               [,1]      [,2]\n  chemical  504.1154  60.05819\n  normal    351.2121  37.69861\n  overt    1002.9565 315.85288\n\n          sspg\nY              [,1]      [,2]\n  chemical 291.7692 177.65479\n  normal   169.0152  65.48952\n  overt    112.6087 106.57253\n```\n:::\n:::\n\n\n**Esta librería asume que las variables numéricas usadas siguen una distriubución normal marginal**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred = predict(a, diabetes[,-4], type = \"raw\")\npred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            chemical        normal        overt\n  [1,]  5.295056e-04  9.990214e-01 4.491287e-04\n  [2,]  2.339643e-03  9.971217e-01 5.386942e-04\n  [3,]  2.275912e-03  9.976460e-01 7.807859e-05\n  [4,]  1.180417e-03  9.987288e-01 9.074437e-05\n  [5,]  4.361057e-03  9.954717e-01 1.672017e-04\n  [6,]  6.386586e-03  9.934653e-01 1.481366e-04\n  [7,]  2.183812e-04  9.996164e-01 1.652600e-04\n  [8,]  1.109668e-02  9.886942e-01 2.091171e-04\n  [9,]  5.561492e-04  9.991428e-01 3.010012e-04\n [10,]  2.860365e-03  9.970620e-01 7.768089e-05\n [11,]  2.737109e-04  9.995964e-01 1.298984e-04\n [12,]  9.429950e-05  9.990956e-01 8.101451e-04\n [13,]  4.685303e-03  9.952171e-01 9.757051e-05\n [14,]  7.145331e-03  9.924505e-01 4.041340e-04\n [15,]  2.577827e-03  9.973178e-01 1.043346e-04\n [16,]  5.755875e-03  9.941035e-01 1.405755e-04\n [17,]  1.940953e-04  9.994795e-01 3.264158e-04\n [18,]  1.206339e-03  9.986771e-01 1.165314e-04\n [19,]  5.334159e-03  9.945073e-01 1.585289e-04\n [20,]  2.698566e-04  9.995533e-01 1.768468e-04\n [21,]  7.047837e-04  9.992159e-01 7.928524e-05\n [22,]  5.066611e-02  9.491241e-01 2.098169e-04\n [23,]  6.040562e-03  9.937900e-01 1.694724e-04\n [24,]  4.388028e-03  9.954543e-01 1.577203e-04\n [25,]  4.236783e-04  9.994793e-01 9.706961e-05\n [26,]  1.851161e-03  9.980173e-01 1.315720e-04\n [27,]  5.266643e-04  9.969041e-01 2.569231e-03\n [28,]  2.002639e-03  9.978337e-01 1.636298e-04\n [29,]  4.942068e-04  9.990224e-01 4.834124e-04\n [30,]  5.673222e-03  9.942287e-01 9.806927e-05\n [31,]  2.769180e-03  9.970957e-01 1.351083e-04\n [32,]  1.196466e-02  9.877739e-01 2.614334e-04\n [33,]  9.187795e-03  9.906305e-01 1.816555e-04\n [34,]  6.866383e-04  9.990540e-01 2.593738e-04\n [35,]  8.178601e-02  9.165555e-01 1.658472e-03\n [36,]  1.860864e-02  9.810572e-01 3.341775e-04\n [37,]  1.232439e-02  9.875490e-01 1.266344e-04\n [38,]  4.917400e-04  9.990449e-01 4.633993e-04\n [39,]  9.000279e-05  9.982301e-01 1.679900e-03\n [40,]  1.080090e-03  9.986026e-01 3.173065e-04\n [41,]  3.708905e-03  9.961129e-01 1.782156e-04\n [42,]  2.054200e-04  9.995771e-01 2.174545e-04\n [43,]  7.433120e-04  9.991504e-01 1.063132e-04\n [44,]  7.221347e-04  9.991566e-01 1.212746e-04\n [45,]  3.258039e-04  9.995439e-01 1.303026e-04\n [46,]  1.254320e-03  9.986309e-01 1.147530e-04\n [47,]  3.679488e-04  9.995214e-01 1.106108e-04\n [48,]  8.575833e-04  9.988566e-01 2.858096e-04\n [49,]  1.275039e-03  9.983903e-01 3.346247e-04\n [50,]  9.521719e-01  4.412351e-02 3.704616e-03\n [51,]  4.828539e-02  9.510608e-01 6.537688e-04\n [52,]  5.440347e-01  4.450488e-01 1.091648e-02\n [53,]  2.667509e-01  7.317704e-01 1.478681e-03\n [54,]  3.289868e-04  9.994252e-01 2.458509e-04\n [55,]  2.113070e-01  7.871383e-01 1.554676e-03\n [56,]  1.067948e-01  8.923053e-01 8.998199e-04\n [57,]  1.784725e-02  9.818881e-01 2.646238e-04\n [58,]  3.200394e-02  9.671740e-01 8.220511e-04\n [59,]  2.527538e-02  9.744571e-01 2.675100e-04\n [60,]  9.727327e-03  9.899078e-01 3.649193e-04\n [61,]  7.682488e-03  9.922034e-01 1.141017e-04\n [62,]  3.744839e-01  6.238293e-01 1.686796e-03\n [63,]  7.721793e-01  2.230828e-01 4.737862e-03\n [64,]  2.003020e-01  7.989477e-01 7.503410e-04\n [65,]  3.440964e-03  9.964530e-01 1.060147e-04\n [66,]  2.381242e-02  9.760112e-01 1.763595e-04\n [67,]  2.275912e-03  9.976460e-01 7.807859e-05\n [68,]  6.761531e-02  9.312615e-01 1.123204e-03\n [69,]  9.994407e-01  5.208362e-04 3.847674e-05\n [70,]  6.424901e-02  9.345319e-01 1.219088e-03\n [71,]  7.408047e-04  9.989515e-01 3.077439e-04\n [72,]  1.000000e+00  2.338103e-22 9.485134e-09\n [73,]  9.786212e-01  5.814184e-06 2.137299e-02\n [74,]  9.999997e-01  5.502353e-11 3.409691e-07\n [75,]  9.850467e-01  1.231466e-07 1.495318e-02\n [76,]  9.999758e-01  1.838167e-09 2.423367e-05\n [77,]  9.999997e-01  7.331410e-15 3.136628e-07\n [78,]  9.803726e-01  1.880635e-02 8.210894e-04\n [79,]  9.932796e-01  2.821303e-09 6.720425e-03\n [80,]  9.810128e-01  1.852270e-02 4.645416e-04\n [81,]  9.999985e-01  3.314769e-11 1.488563e-06\n [82,]  9.987065e-01  4.618651e-06 1.288886e-03\n [83,]  9.999115e-01  3.207163e-05 5.645985e-05\n [84,]  9.602919e-01  3.594148e-02 3.766582e-03\n [85,]  3.592417e-01  6.378324e-01 2.925914e-03\n [86,]  9.990254e-01  5.759318e-06 9.688743e-04\n [87,]  9.821413e-01  4.745440e-07 1.785827e-02\n [88,]  9.777282e-01  2.132689e-02 9.449512e-04\n [89,]  9.678721e-01  5.272532e-07 3.212741e-02\n [90,]  1.012043e-01  8.981187e-01 6.769971e-04\n [91,]  6.472607e-01  1.473760e-12 3.527393e-01\n [92,]  9.923048e-01  6.191171e-05 7.633263e-03\n [93,] 6.897663e-173  0.000000e+00 1.000000e+00\n [94,]  4.976878e-03  2.580640e-21 9.950231e-01\n [95,] 2.477275e-146 1.702646e-304 1.000000e+00\n [96,]  7.133953e-60 2.662460e-137 1.000000e+00\n [97,]  1.166381e-35  1.111443e-88 1.000000e+00\n [98,] 1.851074e-159 5.163499e-300 1.000000e+00\n [99,]  5.174439e-21  5.308143e-55 1.000000e+00\n[100,]  2.488687e-42  2.626983e-96 1.000000e+00\n[101,]  3.141734e-04  1.022311e-15 9.996858e-01\n[102,] 7.579262e-131 5.081788e-267 1.000000e+00\n[103,]  2.659830e-95 1.653866e-183 1.000000e+00\n[104,]  3.774942e-77 5.127724e-169 1.000000e+00\n[105,]  1.938547e-12  2.930057e-45 1.000000e+00\n[106,]  9.973924e-01  1.162370e-10 2.607642e-03\n[107,]  1.467368e-50 3.974579e-111 1.000000e+00\n[108,] 2.314463e-209  0.000000e+00 1.000000e+00\n[109,]  6.664180e-01  1.305333e-07 3.335819e-01\n[110,]  2.259447e-03  1.233813e-18 9.977406e-01\n[111,]  8.066183e-01  1.579498e-13 1.933817e-01\n[112,]  2.863917e-06  7.337970e-28 9.999971e-01\n[113,]  7.552413e-34  1.074422e-84 1.000000e+00\n[114,] 8.805182e-203  0.000000e+00 1.000000e+00\n[115,]  4.892801e-52 4.067389e-116 1.000000e+00\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npred1 = factor(max.col(pred), labels = levels(diabetes$class))\npred1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] normal   normal   normal   normal   normal   normal   normal   normal  \n  [9] normal   normal   normal   normal   normal   normal   normal   normal  \n [17] normal   normal   normal   normal   normal   normal   normal   normal  \n [25] normal   normal   normal   normal   normal   normal   normal   normal  \n [33] normal   normal   normal   normal   normal   normal   normal   normal  \n [41] normal   normal   normal   normal   normal   normal   normal   normal  \n [49] normal   chemical normal   chemical normal   normal   normal   normal  \n [57] normal   normal   normal   normal   normal   normal   chemical normal  \n [65] normal   normal   normal   normal   chemical normal   normal   chemical\n [73] chemical chemical chemical chemical chemical chemical chemical chemical\n [81] chemical chemical chemical chemical normal   chemical chemical chemical\n [89] chemical normal   chemical chemical overt    overt    overt    overt   \n [97] overt    overt    overt    overt    overt    overt    overt    overt   \n[105] overt    chemical overt    overt    chemical overt    chemical overt   \n[113] overt    overt    overt   \nLevels: chemical normal overt\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npred1 = predict(a, diabetes[,-4])\npred1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] normal   normal   normal   normal   normal   normal   normal   normal  \n  [9] normal   normal   normal   normal   normal   normal   normal   normal  \n [17] normal   normal   normal   normal   normal   normal   normal   normal  \n [25] normal   normal   normal   normal   normal   normal   normal   normal  \n [33] normal   normal   normal   normal   normal   normal   normal   normal  \n [41] normal   normal   normal   normal   normal   normal   normal   normal  \n [49] normal   chemical normal   chemical normal   normal   normal   normal  \n [57] normal   normal   normal   normal   normal   normal   chemical normal  \n [65] normal   normal   normal   normal   chemical normal   normal   chemical\n [73] chemical chemical chemical chemical chemical chemical chemical chemical\n [81] chemical chemical chemical chemical normal   chemical chemical chemical\n [89] chemical normal   chemical chemical overt    overt    overt    overt   \n [97] overt    overt    overt    overt    overt    overt    overt    overt   \n[105] overt    chemical overt    overt    chemical overt    chemical overt   \n[113] overt    overt    overt   \nLevels: chemical normal overt\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncaret::confusionMatrix(pred1, diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       20      3     3\n  normal          6     63     0\n  overt           0      0    20\n\nOverall Statistics\n                                          \n               Accuracy : 0.8957          \n                 95% CI : (0.8248, 0.9449)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : 3.778e-14       \n                                          \n                  Kappa : 0.8169          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.7692        0.9545       0.8696\nSpecificity                   0.9326        0.8776       1.0000\nPos Pred Value                0.7692        0.9130       1.0000\nNeg Pred Value                0.9326        0.9348       0.9684\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1739        0.5478       0.1739\nDetection Prevalence          0.2261        0.6000       0.1739\nBalanced Accuracy             0.8509        0.9160       0.9348\n```\n:::\n:::\n\n\n### Sin discretizar ni asumir normalidad\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(naivebayes)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'naivebayes' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nnaivebayes 0.9.7 loaded\n```\n:::\n\n```{.r .cell-code}\na <- naive_bayes(class ~ ., data = diabetes)\na\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n================================== Naive Bayes ================================== \n \n Call: \nnaive_bayes.formula(formula = class ~ ., data = diabetes)\n\n--------------------------------------------------------------------------------- \n \nLaplace smoothing: 0\n\n--------------------------------------------------------------------------------- \n \n A priori probabilities: \n\nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\n--------------------------------------------------------------------------------- \n \n Tables: \n\n--------------------------------------------------------------------------------- \n ::: glucose (Gaussian) \n--------------------------------------------------------------------------------- \n       \nglucose   chemical     normal      overt\n   mean  99.461538  91.984848 207.173913\n   sd     8.805593   8.164637  71.837982\n\n--------------------------------------------------------------------------------- \n ::: insulin (Gaussian) \n--------------------------------------------------------------------------------- \n       \ninsulin   chemical     normal      overt\n   mean  504.11538  351.21212 1002.95652\n   sd     60.05819   37.69861  315.85288\n\n--------------------------------------------------------------------------------- \n ::: sspg (Gaussian) \n--------------------------------------------------------------------------------- \n      \nsspg    chemical    normal     overt\n  mean 291.76923 169.01515 112.60870\n  sd   177.65479  65.48952 106.57253\n\n---------------------------------------------------------------------------------\n```\n:::\n:::\n\n\n**Por default, se asumió normalidad marginal, debido al valor `FALSE` del parámetro `usekernel` de `naive_bayes`**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred = predict(a, diabetes[,-4])\npred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] normal   normal   normal   normal   normal   normal   normal   normal  \n  [9] normal   normal   normal   normal   normal   normal   normal   normal  \n [17] normal   normal   normal   normal   normal   normal   normal   normal  \n [25] normal   normal   normal   normal   normal   normal   normal   normal  \n [33] normal   normal   normal   normal   normal   normal   normal   normal  \n [41] normal   normal   normal   normal   normal   normal   normal   normal  \n [49] normal   chemical normal   chemical normal   normal   normal   normal  \n [57] normal   normal   normal   normal   normal   normal   chemical normal  \n [65] normal   normal   normal   normal   chemical normal   normal   chemical\n [73] chemical chemical chemical chemical chemical chemical chemical chemical\n [81] chemical chemical chemical chemical normal   chemical chemical chemical\n [89] chemical normal   chemical chemical overt    overt    overt    overt   \n [97] overt    overt    overt    overt    overt    overt    overt    overt   \n[105] overt    chemical overt    overt    chemical overt    chemical overt   \n[113] overt    overt    overt   \nLevels: chemical normal overt\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncaret::confusionMatrix(pred,diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       20      3     3\n  normal          6     63     0\n  overt           0      0    20\n\nOverall Statistics\n                                          \n               Accuracy : 0.8957          \n                 95% CI : (0.8248, 0.9449)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : 3.778e-14       \n                                          \n                  Kappa : 0.8169          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.7692        0.9545       0.8696\nSpecificity                   0.9326        0.8776       1.0000\nPos Pred Value                0.7692        0.9130       1.0000\nNeg Pred Value                0.9326        0.9348       0.9684\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1739        0.5478       0.1739\nDetection Prevalence          0.2261        0.6000       0.1739\nBalanced Accuracy             0.8509        0.9160       0.9348\n```\n:::\n\n```{.r .cell-code}\npredict(a, diabetes[,-4], type = \"prob\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            chemical        normal        overt\n  [1,]  5.295056e-04  9.990214e-01 4.491287e-04\n  [2,]  2.339643e-03  9.971217e-01 5.386942e-04\n  [3,]  2.275912e-03  9.976460e-01 7.807859e-05\n  [4,]  1.180417e-03  9.987288e-01 9.074437e-05\n  [5,]  4.361057e-03  9.954717e-01 1.672017e-04\n  [6,]  6.386586e-03  9.934653e-01 1.481366e-04\n  [7,]  2.183812e-04  9.996164e-01 1.652600e-04\n  [8,]  1.109668e-02  9.886942e-01 2.091171e-04\n  [9,]  5.561492e-04  9.991428e-01 3.010012e-04\n [10,]  2.860365e-03  9.970620e-01 7.768089e-05\n [11,]  2.737109e-04  9.995964e-01 1.298984e-04\n [12,]  9.429950e-05  9.990956e-01 8.101451e-04\n [13,]  4.685303e-03  9.952171e-01 9.757051e-05\n [14,]  7.145331e-03  9.924505e-01 4.041340e-04\n [15,]  2.577827e-03  9.973178e-01 1.043346e-04\n [16,]  5.755875e-03  9.941035e-01 1.405755e-04\n [17,]  1.940953e-04  9.994795e-01 3.264158e-04\n [18,]  1.206339e-03  9.986771e-01 1.165314e-04\n [19,]  5.334159e-03  9.945073e-01 1.585289e-04\n [20,]  2.698566e-04  9.995533e-01 1.768468e-04\n [21,]  7.047837e-04  9.992159e-01 7.928524e-05\n [22,]  5.066611e-02  9.491241e-01 2.098169e-04\n [23,]  6.040562e-03  9.937900e-01 1.694724e-04\n [24,]  4.388028e-03  9.954543e-01 1.577203e-04\n [25,]  4.236783e-04  9.994793e-01 9.706961e-05\n [26,]  1.851161e-03  9.980173e-01 1.315720e-04\n [27,]  5.266643e-04  9.969041e-01 2.569231e-03\n [28,]  2.002639e-03  9.978337e-01 1.636298e-04\n [29,]  4.942068e-04  9.990224e-01 4.834124e-04\n [30,]  5.673222e-03  9.942287e-01 9.806927e-05\n [31,]  2.769180e-03  9.970957e-01 1.351083e-04\n [32,]  1.196466e-02  9.877739e-01 2.614334e-04\n [33,]  9.187795e-03  9.906305e-01 1.816555e-04\n [34,]  6.866383e-04  9.990540e-01 2.593738e-04\n [35,]  8.178601e-02  9.165555e-01 1.658472e-03\n [36,]  1.860864e-02  9.810572e-01 3.341775e-04\n [37,]  1.232439e-02  9.875490e-01 1.266344e-04\n [38,]  4.917400e-04  9.990449e-01 4.633993e-04\n [39,]  9.000279e-05  9.982301e-01 1.679900e-03\n [40,]  1.080090e-03  9.986026e-01 3.173065e-04\n [41,]  3.708905e-03  9.961129e-01 1.782156e-04\n [42,]  2.054200e-04  9.995771e-01 2.174545e-04\n [43,]  7.433120e-04  9.991504e-01 1.063132e-04\n [44,]  7.221347e-04  9.991566e-01 1.212746e-04\n [45,]  3.258039e-04  9.995439e-01 1.303026e-04\n [46,]  1.254320e-03  9.986309e-01 1.147530e-04\n [47,]  3.679488e-04  9.995214e-01 1.106108e-04\n [48,]  8.575833e-04  9.988566e-01 2.858096e-04\n [49,]  1.275039e-03  9.983903e-01 3.346247e-04\n [50,]  9.521719e-01  4.412351e-02 3.704616e-03\n [51,]  4.828539e-02  9.510608e-01 6.537688e-04\n [52,]  5.440347e-01  4.450488e-01 1.091648e-02\n [53,]  2.667509e-01  7.317704e-01 1.478681e-03\n [54,]  3.289868e-04  9.994252e-01 2.458509e-04\n [55,]  2.113070e-01  7.871383e-01 1.554676e-03\n [56,]  1.067948e-01  8.923053e-01 8.998199e-04\n [57,]  1.784725e-02  9.818881e-01 2.646238e-04\n [58,]  3.200394e-02  9.671740e-01 8.220511e-04\n [59,]  2.527538e-02  9.744571e-01 2.675100e-04\n [60,]  9.727327e-03  9.899078e-01 3.649193e-04\n [61,]  7.682488e-03  9.922034e-01 1.141017e-04\n [62,]  3.744839e-01  6.238293e-01 1.686796e-03\n [63,]  7.721793e-01  2.230828e-01 4.737862e-03\n [64,]  2.003020e-01  7.989477e-01 7.503410e-04\n [65,]  3.440964e-03  9.964530e-01 1.060147e-04\n [66,]  2.381242e-02  9.760112e-01 1.763595e-04\n [67,]  2.275912e-03  9.976460e-01 7.807859e-05\n [68,]  6.761531e-02  9.312615e-01 1.123204e-03\n [69,]  9.994407e-01  5.208362e-04 3.847674e-05\n [70,]  6.424901e-02  9.345319e-01 1.219088e-03\n [71,]  7.408047e-04  9.989515e-01 3.077439e-04\n [72,]  1.000000e+00  2.338103e-22 9.485134e-09\n [73,]  9.786212e-01  5.814184e-06 2.137299e-02\n [74,]  9.999997e-01  5.502353e-11 3.409691e-07\n [75,]  9.850467e-01  1.231466e-07 1.495318e-02\n [76,]  9.999758e-01  1.838167e-09 2.423367e-05\n [77,]  9.999997e-01  7.331410e-15 3.136628e-07\n [78,]  9.803726e-01  1.880635e-02 8.210894e-04\n [79,]  9.932796e-01  2.821303e-09 6.720425e-03\n [80,]  9.810128e-01  1.852270e-02 4.645416e-04\n [81,]  9.999985e-01  3.314769e-11 1.488563e-06\n [82,]  9.987065e-01  4.618651e-06 1.288886e-03\n [83,]  9.999115e-01  3.207163e-05 5.645985e-05\n [84,]  9.602919e-01  3.594148e-02 3.766582e-03\n [85,]  3.592417e-01  6.378324e-01 2.925914e-03\n [86,]  9.990254e-01  5.759318e-06 9.688743e-04\n [87,]  9.821413e-01  4.745440e-07 1.785827e-02\n [88,]  9.777282e-01  2.132689e-02 9.449512e-04\n [89,]  9.678721e-01  5.272532e-07 3.212741e-02\n [90,]  1.012043e-01  8.981187e-01 6.769971e-04\n [91,]  6.472607e-01  1.473760e-12 3.527393e-01\n [92,]  9.923048e-01  6.191171e-05 7.633263e-03\n [93,] 6.897663e-173  0.000000e+00 1.000000e+00\n [94,]  4.976878e-03  2.580640e-21 9.950231e-01\n [95,] 2.477275e-146 1.702646e-304 1.000000e+00\n [96,]  7.133953e-60 2.662460e-137 1.000000e+00\n [97,]  1.166381e-35  1.111443e-88 1.000000e+00\n [98,] 1.851074e-159 5.163499e-300 1.000000e+00\n [99,]  5.174439e-21  5.308143e-55 1.000000e+00\n[100,]  2.488687e-42  2.626983e-96 1.000000e+00\n[101,]  3.141734e-04  1.022311e-15 9.996858e-01\n[102,] 7.579262e-131 5.081788e-267 1.000000e+00\n[103,]  2.659830e-95 1.653866e-183 1.000000e+00\n[104,]  3.774942e-77 5.127724e-169 1.000000e+00\n[105,]  1.938547e-12  2.930057e-45 1.000000e+00\n[106,]  9.973924e-01  1.162370e-10 2.607642e-03\n[107,]  1.467368e-50 3.974579e-111 1.000000e+00\n[108,] 2.314463e-209  0.000000e+00 1.000000e+00\n[109,]  6.664180e-01  1.305333e-07 3.335819e-01\n[110,]  2.259447e-03  1.233813e-18 9.977406e-01\n[111,]  8.066183e-01  1.579498e-13 1.933817e-01\n[112,]  2.863917e-06  7.337970e-28 9.999971e-01\n[113,]  7.552413e-34  1.074422e-84 1.000000e+00\n[114,] 8.805182e-203  0.000000e+00 1.000000e+00\n[115,]  4.892801e-52 4.067389e-116 1.000000e+00\n```\n:::\n:::\n\n\n**Ahora no asumiremos normalidad marginal**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- naive_bayes(class ~ ., data = diabetes, usekernel = TRUE)\na\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n================================== Naive Bayes ================================== \n \n Call: \nnaive_bayes.formula(formula = class ~ ., data = diabetes, usekernel = TRUE)\n\n--------------------------------------------------------------------------------- \n \nLaplace smoothing: 0\n\n--------------------------------------------------------------------------------- \n \n A priori probabilities: \n\nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\n--------------------------------------------------------------------------------- \n \n Tables: \n\n--------------------------------------------------------------------------------- \n ::: glucose::chemical (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (26 obs.);\tBandwidth 'bw' = 4.131\n\n       x                y            \n Min.   : 72.61   Min.   :4.949e-05  \n 1st Qu.: 86.05   1st Qu.:3.464e-03  \n Median : 99.50   Median :2.127e-02  \n Mean   : 99.50   Mean   :1.857e-02  \n 3rd Qu.:112.95   3rd Qu.:3.093e-02  \n Max.   :126.39   Max.   :3.998e-02  \n\n--------------------------------------------------------------------------------- \n ::: glucose::normal (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (66 obs.);\tBandwidth 'bw' = 3.179\n\n       x                y            \n Min.   : 60.46   Min.   :2.145e-05  \n 1st Qu.: 75.73   1st Qu.:2.132e-03  \n Median : 91.00   Median :8.905e-03  \n Mean   : 91.00   Mean   :1.636e-02  \n 3rd Qu.:106.27   3rd Qu.:3.114e-02  \n Max.   :121.54   Max.   :4.846e-02  \n\n--------------------------------------------------------------------------------- \n ::: glucose::overt (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (23 obs.);\tBandwidth 'bw' = 34.53\n\n       x               y            \n Min.   : 16.4   Min.   :8.447e-06  \n 1st Qu.:122.9   1st Qu.:5.362e-04  \n Median :229.5   Median :2.638e-03  \n Mean   :229.5   Mean   :2.343e-03  \n 3rd Qu.:336.1   3rd Qu.:3.926e-03  \n Max.   :442.6   Max.   :4.754e-03  \n\n--------------------------------------------------------------------------------- \n ::: insulin::chemical (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (26 obs.);\tBandwidth 'bw' = 28.17\n\n       x               y            \n Min.   :338.5   Min.   :6.131e-06  \n 1st Qu.:435.7   1st Qu.:4.410e-04  \n Median :533.0   Median :2.180e-03  \n Mean   :533.0   Mean   :2.567e-03  \n 3rd Qu.:630.3   3rd Qu.:4.770e-03  \n Max.   :727.5   Max.   :5.687e-03  \n\n--------------------------------------------------------------------------------- \n ::: insulin::normal (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (66 obs.);\tBandwidth 'bw' = 14.68\n\n       x               y            \n Min.   :225.0   Min.   :4.725e-06  \n 1st Qu.:286.2   1st Qu.:5.085e-04  \n Median :347.5   Median :3.890e-03  \n Mean   :347.5   Mean   :4.076e-03  \n 3rd Qu.:408.8   3rd Qu.:7.314e-03  \n Max.   :470.0   Max.   :9.098e-03  \n\n--------------------------------------------------------------------------------- \n ::: insulin::overt (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (23 obs.);\tBandwidth 'bw' = 151.8\n\n       x                 y            \n Min.   :  82.48   Min.   :2.495e-06  \n 1st Qu.: 555.74   1st Qu.:1.141e-04  \n Median :1029.00   Median :6.280e-04  \n Mean   :1029.00   Mean   :5.276e-04  \n 3rd Qu.:1502.26   3rd Qu.:8.772e-04  \n Max.   :1975.52   Max.   :1.019e-03  \n\n--------------------------------------------------------------------------------- \n ::: sspg::chemical (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (26 obs.);\tBandwidth 'bw' = 60.82\n\n       x                y            \n Min.   :-73.47   Min.   :2.835e-06  \n 1st Qu.:177.52   1st Qu.:2.706e-04  \n Median :428.50   Median :6.522e-04  \n Mean   :428.50   Mean   :9.949e-04  \n 3rd Qu.:679.48   3rd Qu.:1.536e-03  \n Max.   :930.47   Max.   :3.155e-03  \n\n--------------------------------------------------------------------------------- \n ::: sspg::normal (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (66 obs.);\tBandwidth 'bw' = 19.76\n\n       x                y            \n Min.   : 13.73   Min.   :1.000e-09  \n 1st Qu.:147.61   1st Qu.:2.739e-05  \n Median :281.50   Median :3.686e-04  \n Mean   :281.50   Mean   :1.865e-03  \n 3rd Qu.:415.39   3rd Qu.:2.967e-03  \n Max.   :549.27   Max.   :7.958e-03  \n\n--------------------------------------------------------------------------------- \n ::: sspg::overt (KDE)\n--------------------------------------------------------------------------------- \n\nCall:\n\tdensity.default(x = x, na.rm = TRUE)\n\nData: x (23 obs.);\tBandwidth 'bw' = 31.39\n\n       x                y            \n Min.   :-84.17   Min.   :6.215e-06  \n 1st Qu.: 75.41   1st Qu.:2.632e-04  \n Median :235.00   Median :5.806e-04  \n Mean   :235.00   Mean   :1.565e-03  \n 3rd Qu.:394.59   3rd Qu.:2.299e-03  \n Max.   :554.17   Max.   :5.651e-03  \n\n---------------------------------------------------------------------------------\n```\n:::\n\n```{.r .cell-code}\nplot(a)\n```\n\n::: {.cell-output-display}\n![](clase-05_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](clase-05_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](clase-05_files/figure-html/unnamed-chunk-11-3.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npred = predict(a, diabetes[,-4])\npred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] normal   normal   normal   normal   normal   normal   normal   normal  \n  [9] normal   normal   normal   normal   normal   normal   normal   normal  \n [17] normal   normal   normal   normal   normal   normal   normal   normal  \n [25] normal   normal   normal   normal   normal   normal   normal   normal  \n [33] normal   normal   normal   normal   normal   normal   normal   normal  \n [41] normal   normal   normal   normal   normal   normal   normal   normal  \n [49] normal   chemical normal   chemical chemical normal   normal   normal  \n [57] normal   normal   normal   normal   normal   normal   chemical normal  \n [65] normal   normal   normal   normal   normal   normal   normal   chemical\n [73] chemical chemical chemical chemical chemical chemical chemical chemical\n [81] chemical chemical chemical chemical chemical chemical chemical chemical\n [89] chemical normal   chemical chemical overt    overt    overt    overt   \n [97] overt    overt    overt    overt    overt    overt    overt    overt   \n[105] overt    chemical overt    overt    chemical overt    chemical overt   \n[113] overt    overt    overt   \nLevels: chemical normal overt\n```\n:::\n\n```{.r .cell-code}\ncaret::confusionMatrix(pred, diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       22      2     3\n  normal          4     64     0\n  overt           0      0    20\n\nOverall Statistics\n                                          \n               Accuracy : 0.9217          \n                 95% CI : (0.8566, 0.9636)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.8634          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8462        0.9697       0.8696\nSpecificity                   0.9438        0.9184       1.0000\nPos Pred Value                0.8148        0.9412       1.0000\nNeg Pred Value                0.9545        0.9574       0.9684\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1913        0.5565       0.1739\nDetection Prevalence          0.2348        0.5913       0.1739\nBalanced Accuracy             0.8950        0.9440       0.9348\n```\n:::\n:::\n\n\n### Discretizar usando Chi-Merge\n\n- Una **discretización no supervisada** no toma en cuenta\nlos valores de la response, al momento de discretizar uno \no más predictores.\n\n- Por otro lado, la [discretización supervisada](https://www.futurelearn.com/info/courses/more-data-mining-with-weka/0/steps/29114) **sí considera la respuesta** al momento de discretizar\nuno o más predictores, con el fin de crear intervalos de \ndiscretización que maximicen la probabilidad de predecir\nadecuadamente una **training observation**, no de tipo **testing**.\n\n- [Chi-Merge](https://sci2s.ugr.es/keel/pdf/algorithm/congreso/1992-Kerber-ChimErge-AAAI92.pdf)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Discretizando por el método Chi-Merge\nlibrary(discretization)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'discretization' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\n# Discretizamos todas las columnas, salvo la última.\nd_diab = chiM(diabetes, 0.01)$Disc.data\n\n# Discretizamos solo la primera y tercera columnas\n# d_diab = chiM(diabetes[, c(1, 3)], 0.01)$Disc.data\n\n\n# Convertimos a categórica para evitar que la función\n# naive_bayes asuma con variables numéricas (gaussianas o no)\nfor (i in 1:3) {\n  d_diab[,i] <- as.factor(d_diab[,i])\n}\n\nd_diab\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    glucose insulin sspg    class\n1         1       1    2   normal\n2         2       1    3   normal\n3         1       1    3   normal\n4         1       1    3   normal\n5         1       1    3   normal\n6         1       1    3   normal\n7         1       1    3   normal\n8         1       1    3   normal\n9         1       1    2   normal\n10        1       1    3   normal\n11        1       1    3   normal\n12        1       1    2   normal\n13        1       1    3   normal\n14        1       1    3   normal\n15        1       1    3   normal\n16        1       1    3   normal\n17        1       1    2   normal\n18        1       1    2   normal\n19        1       1    2   normal\n20        1       1    2   normal\n21        1       1    3   normal\n22        1       1    3   normal\n23        1       1    3   normal\n24        1       1    3   normal\n25        1       1    3   normal\n26        1       1    3   normal\n27        1       1    2   normal\n28        1       1    3   normal\n29        1       1    3   normal\n30        1       1    3   normal\n31        1       1    3   normal\n32        1       1    2   normal\n33        1       1    3   normal\n34        1       1    3   normal\n35        2       1    2   normal\n36        2       1    3   normal\n37        1       1    3   normal\n38        1       1    2   normal\n39        1       1    2   normal\n40        1       1    2   normal\n41        1       1    2   normal\n42        1       1    3   normal\n43        1       1    3   normal\n44        1       1    3   normal\n45        1       1    3   normal\n46        1       1    3   normal\n47        1       1    3   normal\n48        1       1    2   normal\n49        1       1    2   normal\n50        1       2    3 chemical\n51        1       1    2   normal\n52        2       2    2   normal\n53        1       2    3 chemical\n54        1       1    2   normal\n55        1       2    3 chemical\n56        1       1    2   normal\n57        1       1    2   normal\n58        1       1    3   normal\n59        1       1    3   normal\n60        1       1    2   normal\n61        1       1    3   normal\n62        2       1    3   normal\n63        2       1    3   normal\n64        1       2    3 chemical\n65        1       1    3   normal\n66        1       1    3   normal\n67        1       1    3   normal\n68        1       1    2   normal\n69        1       1    4   normal\n70        1       2    3 chemical\n71        1       1    2   normal\n72        2       2    4 chemical\n73        2       2    3 chemical\n74        2       2    4 chemical\n75        2       2    3 chemical\n76        2       2    4 chemical\n77        2       2    4 chemical\n78        1       2    4 chemical\n79        2       2    3 chemical\n80        1       2    4 chemical\n81        1       2    4 chemical\n82        2       2    4 chemical\n83        1       2    4 chemical\n84        2       2    3 chemical\n85        1       2    2 chemical\n86        1       2    4 chemical\n87        1       2    2 chemical\n88        1       2    4 chemical\n89        2       2    2 chemical\n90        1       2    3 chemical\n91        2       2    3 chemical\n92        2       2    2 chemical\n93        3       3    1    overt\n94        3       3    3    overt\n95        3       3    1    overt\n96        3       3    2    overt\n97        3       3    2    overt\n98        3       3    1    overt\n99        3       3    2    overt\n100       3       3    2    overt\n101       3       2    2    overt\n102       3       3    1    overt\n103       3       3    2    overt\n104       3       3    2    overt\n105       3       3    2    overt\n106       3       2    4    overt\n107       3       3    1    overt\n108       3       3    1    overt\n109       3       2    2    overt\n110       3       3    1    overt\n111       3       2    4    overt\n112       3       3    3    overt\n113       3       3    2    overt\n114       3       3    1    overt\n115       3       3    1    overt\n```\n:::\n:::\n\n\n**Esta librería asume que la última columna del data frame es la de la clase que deseamos predecir.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sin corrección de Laplace (observar prob. cond.)\nb0 <- naive_bayes(class ~ ., data = d_diab)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: naive_bayes(): Feature glucose - zero probabilities are present.\nConsider Laplace smoothing.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: naive_bayes(): Feature insulin - zero probabilities are present.\nConsider Laplace smoothing.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: naive_bayes(): Feature sspg - zero probabilities are present. Consider\nLaplace smoothing.\n```\n:::\n\n```{.r .cell-code}\nb0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n================================== Naive Bayes ================================== \n \n Call: \nnaive_bayes.formula(formula = class ~ ., data = d_diab)\n\n--------------------------------------------------------------------------------- \n \nLaplace smoothing: 0\n\n--------------------------------------------------------------------------------- \n \n A priori probabilities: \n\nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\n--------------------------------------------------------------------------------- \n \n Tables: \n\n--------------------------------------------------------------------------------- \n ::: glucose (Categorical) \n--------------------------------------------------------------------------------- \n       \nglucose   chemical     normal      overt\n      1 0.53846154 0.90909091 0.00000000\n      2 0.46153846 0.09090909 0.00000000\n      3 0.00000000 0.00000000 1.00000000\n\n--------------------------------------------------------------------------------- \n ::: insulin (Categorical) \n--------------------------------------------------------------------------------- \n       \ninsulin   chemical     normal      overt\n      1 0.00000000 0.98484848 0.00000000\n      2 1.00000000 0.01515152 0.17391304\n      3 0.00000000 0.00000000 0.82608696\n\n--------------------------------------------------------------------------------- \n ::: sspg (Categorical) \n--------------------------------------------------------------------------------- \n    \nsspg   chemical     normal      overt\n   1 0.00000000 0.00000000 0.39130435\n   2 0.15384615 0.36363636 0.43478261\n   3 0.42307692 0.62121212 0.08695652\n   4 0.42307692 0.01515152 0.08695652\n\n---------------------------------------------------------------------------------\n```\n:::\n\n```{.r .cell-code}\n# Aplicando laplaciano = 1\nb1 <- naive_bayes(class ~ ., data = d_diab, laplace = 1)\nb1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n================================== Naive Bayes ================================== \n \n Call: \nnaive_bayes.formula(formula = class ~ ., data = d_diab, laplace = 1)\n\n--------------------------------------------------------------------------------- \n \nLaplace smoothing: 1\n\n--------------------------------------------------------------------------------- \n \n A priori probabilities: \n\nchemical   normal    overt \n0.226087 0.573913 0.200000 \n\n--------------------------------------------------------------------------------- \n \n Tables: \n\n--------------------------------------------------------------------------------- \n ::: glucose (Categorical) \n--------------------------------------------------------------------------------- \n       \nglucose   chemical     normal      overt\n      1 0.51724138 0.88405797 0.03846154\n      2 0.44827586 0.10144928 0.03846154\n      3 0.03448276 0.01449275 0.92307692\n\n--------------------------------------------------------------------------------- \n ::: insulin (Categorical) \n--------------------------------------------------------------------------------- \n       \ninsulin   chemical     normal      overt\n      1 0.03448276 0.95652174 0.03846154\n      2 0.93103448 0.02898551 0.19230769\n      3 0.03448276 0.01449275 0.76923077\n\n--------------------------------------------------------------------------------- \n ::: sspg (Categorical) \n--------------------------------------------------------------------------------- \n    \nsspg   chemical     normal      overt\n   1 0.03333333 0.01428571 0.37037037\n   2 0.16666667 0.35714286 0.40740741\n   3 0.40000000 0.60000000 0.11111111\n   4 0.40000000 0.02857143 0.11111111\n\n---------------------------------------------------------------------------------\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npred0 = predict(b0, d_diab[,-4])\ncaret::confusionMatrix(pred0, d_diab[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       26      1     0\n  normal          0     65     0\n  overt           0      0    23\n\nOverall Statistics\n                                          \n               Accuracy : 0.9913          \n                 95% CI : (0.9525, 0.9998)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.9851          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   1.0000        0.9848          1.0\nSpecificity                   0.9888        1.0000          1.0\nPos Pred Value                0.9630        1.0000          1.0\nNeg Pred Value                1.0000        0.9800          1.0\nPrevalence                    0.2261        0.5739          0.2\nDetection Rate                0.2261        0.5652          0.2\nDetection Prevalence          0.2348        0.5652          0.2\nBalanced Accuracy             0.9944        0.9924          1.0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npred1 = predict(b1, d_diab[,-4])\ncaret::confusionMatrix(pred1, d_diab[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       26      1     0\n  normal          0     65     0\n  overt           0      0    23\n\nOverall Statistics\n                                          \n               Accuracy : 0.9913          \n                 95% CI : (0.9525, 0.9998)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.9851          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   1.0000        0.9848          1.0\nSpecificity                   0.9888        1.0000          1.0\nPos Pred Value                0.9630        1.0000          1.0\nNeg Pred Value                1.0000        0.9800          1.0\nPrevalence                    0.2261        0.5739          0.2\nDetection Rate                0.2261        0.5652          0.2\nDetection Prevalence          0.2348        0.5652          0.2\nBalanced Accuracy             0.9944        0.9924          1.0\n```\n:::\n:::\n\n\n### Testing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Datos de Prueba\ndiabetes_test = read.csv(\"../datos/DiabetesTest.csv\")\ndiabetes_test$class <- as.factor(diabetes_test$class)\n\nhead(diabetes_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  glucose insulin sspg    class\n1      89     472  162 chemical\n2      96     465  237 chemical\n3     112     503  408 chemical\n4     110     477  124 chemical\n5      90     413  344 chemical\n6     102     472  297 chemical\n```\n:::\n\n```{.r .cell-code}\ncaret::confusionMatrix(\n  predict(a, diabetes_test[,-4]), diabetes_test[,4]\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical        9      1     0\n  normal          1      9     0\n  overt           0      0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.9333          \n                 95% CI : (0.7793, 0.9918)\n    No Information Rate : 0.3333          \n    P-Value [Acc > NIR] : 8.747e-12       \n                                          \n                  Kappa : 0.9             \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.9000        0.9000       1.0000\nSpecificity                   0.9500        0.9500       1.0000\nPos Pred Value                0.9000        0.9000       1.0000\nNeg Pred Value                0.9500        0.9500       1.0000\nPrevalence                    0.3333        0.3333       0.3333\nDetection Rate                0.3000        0.3000       0.3333\nDetection Prevalence          0.3333        0.3333       0.3333\nBalanced Accuracy             0.9250        0.9250       1.0000\n```\n:::\n:::\n\n\n::: {#thm-}\n\nSi se discretizó el **training set**, usar esos \n**mismos intervalos de discretazicación** para el \n**testing set**.\n\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Intervalos de discretización\nalpha <- 0.01\nd <- chiM(diabetes, alpha)\nd$cutp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 100.5 117.0\n\n[[2]]\n[1] 420.5 656.5\n\n[[3]]\n[1]  63.5 140.5 283.5\n```\n:::\n:::\n\n\n**El nivel de discretización** (`alpha`) también es un\n**hiperparámtro**.\n\n::: {#prp-}\n\nEjercicio\n\nDiscretizar el testing dataset usando los intervalos de discretización del training dataset, para\nevaluar la matriz de confusión asociada a los modelos `b0` y `b1`.\n\n:::\n\n::: {#prp-}\n\nEjercicio\n\nImplementar un `for loop` para el hiperparámetro `alpha`, \ny obtener la matriz de confusión asociada al modelo\ncon discretización Chi-Merge.\n\n:::\n\n\n## K-vecinos más cercanos (KNN)\n\n- **No es eficiente para inferencia**, es decir,\nentender el efecto de predictores sobre la response.\n\n- Útil para **regresión y clasificación**.\n\n- **Difícil de intepretar**.\n\n- No le afecta si son varias clases para respuesta.\n\n- Llega a **demorar computacionalmente** para altos volúmenes de datos, por lo que **no es un algoritmo escalable**.\n\n- Se le considera un **lazy algorithm**, pues no estima nada,\nno es que genere una *función de predicción*, como hemos \nvimos en otros algoritmos. \\ \nPor ello, si se aumenta la cantidad de datos de entrenamiento,\nhabría que ejecutar **todo el algoritmo de nuevo**.\n\n- Se emplea para **predictores numéricos**.\n\n- Se deben **estandarizar los datos** (mapeándolos al intervalo\n$\\left( 0,1 \\right)$ por ejemplo), puesto que las unidades de\nlos predictores pueden alterar la *noción de cercanía*.\n\n- Se emplea para **predictores numéricos**.\n\n- Se deben **estandarizar los datos** (mapeándolos al intervalo\n$\\left( 0,1 \\right)$ por ejemplo), puesto que las unidades de\nlos predictores pueden alterar la *noción de cercanía*.\n\n- En el caso se desee usar **predictores categóricos** en el modelo, se tienen algunas alternativas:\n    - Estimar **variables latentes** asociadas a predictores\n    categóricos (lo veremos en *Stats. Learning 2*)\n    - **Binarizar** las variables categóricas, pero \n    **sin descartar** las columnas consideradas *extra*, \n    cuando se hace el tratamiento de *dummy variables*.\n\n### Pasos\n\n1. Elegimos dos parámetros:\n    - **Métrica** para calcular distancias.\n    - Valor de **K** (número de vecinos a considerar).\n\n1. Dada una observación $x_0$, buscar los $K$ puntos de\n**datos de entrenamiento** más cercanos a $x_0$.\n\n1. Estos $K$ puntos forman la vecindad $\\mathcal{N}_0$ de $x_0$.\n\n1. La clasificación se realiza vía algún tipo de promedio.\nPor ejemplo, **media** (ponderada o no) para el caso de **regresión**; y, **moda**, para el caso de **clasificación**.\n\n### ¿Cómo elegir K?\n\n- $K = 1$ genera un modelo **muy flexible**.\n- $K$ muy grande puede generar una separación via un hiperplano,\npor lo que se espera un resultado similar a usar Análisis Discriminante.\n\n## Ejemplo práctico\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(class)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'class' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\nb <- knn(\n  # Repetimos los datos, por fines ilustrativos\n  train = diabetes[,1:3], test = diabetes[,1:3],\n  cl = diabetes[,4]\n  # Por default, K vale 1\n)\nb\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] normal   normal   normal   normal   normal   normal   normal   normal  \n  [9] normal   normal   normal   normal   normal   normal   normal   normal  \n [17] normal   normal   normal   normal   normal   normal   normal   normal  \n [25] normal   normal   normal   normal   normal   normal   normal   normal  \n [33] normal   normal   normal   normal   normal   normal   normal   normal  \n [41] normal   normal   normal   normal   normal   normal   normal   normal  \n [49] normal   chemical normal   normal   chemical normal   chemical normal  \n [57] normal   normal   normal   normal   normal   normal   normal   chemical\n [65] normal   normal   normal   normal   normal   chemical normal   chemical\n [73] chemical chemical chemical chemical chemical chemical chemical chemical\n [81] chemical chemical chemical chemical chemical chemical chemical chemical\n [89] chemical chemical chemical chemical overt    overt    overt    overt   \n [97] overt    overt    overt    overt    overt    overt    overt    overt   \n[105] overt    overt    overt    overt    overt    overt    overt    overt   \n[113] overt    overt    overt   \nLevels: chemical normal overt\n```\n:::\n\n```{.r .cell-code}\n# Estimacion del error por resubstitución\ncaret::confusionMatrix(b, diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       26      0     0\n  normal          0     66     0\n  overt           0      0    23\n\nOverall Statistics\n                                     \n               Accuracy : 1          \n                 95% CI : (0.9684, 1)\n    No Information Rate : 0.5739     \n    P-Value [Acc > NIR] : < 2.2e-16  \n                                     \n                  Kappa : 1          \n                                     \n Mcnemar's Test P-Value : NA         \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   1.0000        1.0000          1.0\nSpecificity                   1.0000        1.0000          1.0\nPos Pred Value                1.0000        1.0000          1.0\nNeg Pred Value                1.0000        1.0000          1.0\nPrevalence                    0.2261        0.5739          0.2\nDetection Rate                0.2261        0.5739          0.2\nDetection Prevalence          0.2261        0.5739          0.2\nBalanced Accuracy             1.0000        1.0000          1.0\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# con K=3\nk_3 <- knn(\n  train = diabetes[,1:3], test = diabetes[,1:3],\n  cl = diabetes[,4], k = 3\n)\ncaret::confusionMatrix(k_3, diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       25      1     4\n  normal          1     65     0\n  overt           0      0    19\n\nOverall Statistics\n                                          \n               Accuracy : 0.9478          \n                 95% CI : (0.8899, 0.9806)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : < 2.2e-16       \n                                          \n                  Kappa : 0.9098          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.9615        0.9848       0.8261\nSpecificity                   0.9438        0.9796       1.0000\nPos Pred Value                0.8333        0.9848       1.0000\nNeg Pred Value                0.9882        0.9796       0.9583\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.2174        0.5652       0.1652\nDetection Prevalence          0.2609        0.5739       0.1652\nBalanced Accuracy             0.9527        0.9822       0.9130\n```\n:::\n\n```{.r .cell-code}\nmean(k_3 == diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9478261\n```\n:::\n\n```{.r .cell-code}\n# con K=7\nk_7 <- knn(\n  train = diabetes[,1:3], test = diabetes[,1:3],\n  cl = diabetes[,4], k = 7\n)\ncaret::confusionMatrix(k_7, diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       22      1     5\n  normal          4     65     0\n  overt           0      0    18\n\nOverall Statistics\n                                          \n               Accuracy : 0.913           \n                 95% CI : (0.8459, 0.9575)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : 8.022e-16       \n                                          \n                  Kappa : 0.8473          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8462        0.9848       0.7826\nSpecificity                   0.9326        0.9184       1.0000\nPos Pred Value                0.7857        0.9420       1.0000\nNeg Pred Value                0.9540        0.9783       0.9485\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1913        0.5652       0.1565\nDetection Prevalence          0.2435        0.6000       0.1565\nBalanced Accuracy             0.8894        0.9516       0.8913\n```\n:::\n\n```{.r .cell-code}\nmean(k_7 == diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9130435\n```\n:::\n\n```{.r .cell-code}\n# con K=15\nk_15 <- knn(\n  train = diabetes[,1:3], test = diabetes[,1:3],\n  cl = diabetes[,4], k = 15\n)\ncaret::confusionMatrix(k_15, diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical       20      1     5\n  normal          6     65     0\n  overt           0      0    18\n\nOverall Statistics\n                                          \n               Accuracy : 0.8957          \n                 95% CI : (0.8248, 0.9449)\n    No Information Rate : 0.5739          \n    P-Value [Acc > NIR] : 3.778e-14       \n                                          \n                  Kappa : 0.8147          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.7692        0.9848       0.7826\nSpecificity                   0.9326        0.8776       1.0000\nPos Pred Value                0.7692        0.9155       1.0000\nNeg Pred Value                0.9326        0.9773       0.9485\nPrevalence                    0.2261        0.5739       0.2000\nDetection Rate                0.1739        0.5652       0.1565\nDetection Prevalence          0.2261        0.6174       0.1565\nBalanced Accuracy             0.8509        0.9312       0.8913\n```\n:::\n\n```{.r .cell-code}\nmean(k_15 == diabetes[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8956522\n```\n:::\n:::\n\n\n### Testing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aplicando K=3 en los datos de test\ndiabetes_test = read.csv(\"../datos/DiabetesTest.csv\")\ndiabetes_test$class <- as.factor(diabetes_test$class)\n\nK_3 <- knn(\n  train = diabetes[,1:3], test = diabetes_test[,-4],\n  cl = diabetes[,4], k = 3, prob = TRUE\n)\n\n# Obtener la proporción de votos para la clase ganadora\nK_3_prob <- attr(K_3, \"prob\")\n\n# Valores predichos\nhead(K_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] chemical chemical chemical chemical normal   chemical\nLevels: chemical normal overt\n```\n:::\n\n```{.r .cell-code}\n# Proporciones de \"votos\"\nhead(K_3_prob)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.0000000 1.0000000 0.6666667 1.0000000 0.6666667 1.0000000\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncaret::confusionMatrix(K_3, diabetes_test[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction chemical normal overt\n  chemical        8      0     0\n  normal          2     10     0\n  overt           0      0    10\n\nOverall Statistics\n                                          \n               Accuracy : 0.9333          \n                 95% CI : (0.7793, 0.9918)\n    No Information Rate : 0.3333          \n    P-Value [Acc > NIR] : 8.747e-12       \n                                          \n                  Kappa : 0.9             \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: chemical Class: normal Class: overt\nSensitivity                   0.8000        1.0000       1.0000\nSpecificity                   1.0000        0.9000       1.0000\nPos Pred Value                1.0000        0.8333       1.0000\nNeg Pred Value                0.9091        1.0000       1.0000\nPrevalence                    0.3333        0.3333       0.3333\nDetection Rate                0.2667        0.3333       0.3333\nDetection Prevalence          0.2667        0.4000       0.3333\nBalanced Accuracy             0.9000        0.9500       1.0000\n```\n:::\n:::",
    "supporting": [
      "clase-05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}